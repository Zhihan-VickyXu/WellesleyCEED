Paper Title,Authors,Section Title,Ethics
How Do US Congress Members Advertise Climate Change: An Analysis of Ads Run on Meta’s Platforms,"Laurenz Aisenpreis, Gustav Gyrst, Vedran Sekara",Ethical Statement,"The data in this paper is derived from the Meta Ad Library. It contains publicly accessible ads run on Meta platforms by US politicians. Working with social media data carries risks of privacy issues and the right to be forgotten. However, our data analysis is limited to aggregated data presentations and only concerns ads published by public figures."
The Pursuit of Peer Support for Opioid Use Recovery on Reddit,"Duilio Balsamo, Paolo Bajardi, Gianmarco De Francisci Morales, Corrado Monti, Rossano Schifanella",Ethical Statement,"This work follows the guidelines and the ethical considerations by Eysenbach and Till (2001); Moreno et al. (2013); Ramırez-Cifuentes et al. (2020). All the results provide aggregated estimates and do not include any information on individuals. The users in our study were fully aware of  the  public  nature  and  free  accessibility  of  the  content they posted since the subreddits are of public domain, are not password-protected, and have thousands of active subscribers.  Reddit’s  pseudonymous  accounts  make  the  retrieval  of  the  true  identity  of  users  unlikely.  Nevertheless, as  a  further  privacy  measure,  the  authors’  names  were anonymized before  using the data  for analysis.  Therefore, our research did not require informed consent."
Exposure to Marginally Abusive Content on Twitter,"Jack Bandy, Tomo Lazovich",Ethics Statement,"This study intersects with a number of topics related to the ethics of algorithmic platforms. For example, our analysis requires collecting data about which Tweets users view while using Twitter, and also requires human annotators to review and rate potentially abusive content. Overall, we agree with researchers who view this type of work as necessary for understanding and protecting democratic discourse (Fiske 2022), especially in terms of standard risk-benefit frameworks. Still, it is important to note different measures taken to address potential risks. While the holdback experiment is necessary, it is not ideal for many users to be excluded from algorithmic timeline features. Twitter has thus worked to provide more users access to algorithmic timelines while maintaining statistical robustness in the holdback experiment. As of 2020, the experiment included over 2 million active accounts in the reverse-chronological timeline group (Husz ́ar et al. 2022), but when this analysis was conducted in 2021, that number had been reduced to 630k. This study was not subject to an academic IRB process, however, it went through standard legal and privacy review processes at Twitter. Finally, the data used in this paper was fully anonymized for publication, following standard ethical procedures. We do not include any results that might disclose the identity of any account in the datasets."
Finding Qs: Profiling QAnon Supporters on Parler,"Dominik Bär, Nicolas Pröllochs, Stefan Feuerriegel",Ethics Statement,"This research did not involve interventions with human subjects, and, thus, no approval from the Institutional Review Board was required by the author institutions. All analyses are based on publicly available data and we do not make any attempt to track users across different platforms. We neither de-anonymize nor de-identify their accounts. Furthermore  all analyses conform with national laws. To respect privacy, we explicitly do not publish usernames in our paper (except for celebrity profiles) and only report aggregate results."
Predicting Future Location Categories of Users in a Large Social Platform,"Raiyan Abdul Baten, Yozen Liu, Heinrich Peters, Francesco Barbieri, Neil Shah, Leonardo Neves, Maarten W. Bos",Ethics Statement,"Any experiment dealing with data as sensitive as ours (e.g.,location) needs to operate ethically and securely. Our approach actively aims to minimize risks of misuse and intrusion by avoiding user-identifiable data, such as demographic identities and spatial coordinates. Thus, our model may be preferable in highly sensitive settings. The datasets were anonymized before analysis. All experiments were conducted in Snapchat’s internal secure storage systems, and no data was stored outside Snapchat’s ecosystem. Thus, we do not foresee strong ethical concerns induced by our work."
"Followback Clusters, Satellite Audiences, and Bridge Nodes: Coengagement Networks for the 2020 US Election","Andrew Beers, Joseph S. Schafer, Ian Kennedy, Morgan Wack, Emma S. Spiro, Kate Starbird","Ethical Considerations, Limitations, and SoftwareSharing","As network visualizations continue to be central in social media analysis, we believe it is necessary to briefly examine the ethical considerations on whether network visualizations such as these should be used in every circumstance. We have chosen here to visualize users participating in a high-prominence topic, consisting of mostly public-facing accounts such as politicians and media outlets. The same methods applied to communities with a higher expectation of privacy, or who face higher risks from exposure, may be unethical surveillance if researchers have not derived consent from members of these communities. There are also ethical implications to naming accounts visualized as nodes in networks. Some users, due to gender, race, or other factors, are at higher risk of harassment if identified as influential in a given community, while other users who explicitly seek attention in online communities may use their identification in networks as a propaganda tool in hateful campaigns. In our reporting of this work, we have declined to name some accounts for both reasons. We also stress here how the data collection procedure, and subsequent description of that procedure, affects which communities appear to be participating in a phenomenon. Several politically-active Twitter communities in the US that have been previously described in research, such as Black Twitter (Clark 2019) and non-English language communities (Fang 2021; Soto-Vasquez et al. 2020), are not explicitly visible in our analysis, likely due to their different posting volumes and the choice of terms and topics on which we chose to center our data collection. Researchers working with such visualizations whose research bears on policy and public perception must explain such limitations in the communication of theirwork. We have described the basic form of an approach for visualizing engagements in social network data, and there are many ways in which this method can be modified to more saliently  capture  engagement  dynamics.  For  example,  the current formulation of this method places emphasis on users who frequently share content, which is not necessarily undesirable given the external impact of this behavior. However, different  formulations  of  the  network  projection  scheme, such as those that weight users’ engagements relative to their average level of engagement, may be a better reflection of real discourse communities that exist at lower sharing volumes.  We  also  observe  that  many  of  these  coengagement networks create densely-connected subgraphs in which most nodes are connected to most other nodes, making internode relationships difficult to visually identify. Accordingly, these networks may be complementary with other techniques to improve visualizations of social networks, such as the edge sparsification  procedures  for  densely-connected  networks proposed by Nocaj et al. (2015). In  the  hopes  that  others  may  replicate  our  methods  of both visualization and analysis on new datasets, we make the code available for generating these graphs either from structured data received from the Twitter API, or in general JSON and CSV-based formats. This code uses the visualization capabilities of the open-source network visualization library Gephi, and its implementation of the ForceAtlas algorithm for network visualization (Bastian, Heymann, and Jacomy2009; Jacomy et al. 2014). We have packaged this code in publicly-available  Docker  containers,  a  relatively  portable and stable code format which can be run on many machines with relatively few installation requirements. Additionally, we have made available node and link data for all visualizations displayed in this paper, as well as a list of Twitter ID numbers for tweets and users corresponding to data used to generate these graphs. We hope by making the code for generating these graphs open-source, other researchers both qualitative and quantitative will both explore the potential and limitations of this method, as well as contribute modifications to this scheme as appropriate."
Measuring the Ideology of Audiences for Web Links and Domains Using Differentially Private Engagement Data,"Cody Buntain, Richard Bonneau, Jonathan Nagler, Joshua A. Tucker",Ethics and Competing Interests,"This  work’s  intent  is  to  provide  a  broader  audience  withan example for working with social media and digital tracedata that has been protected with differential privacy tech-niques. Though this work is focused on audience ideology, the  methods  are  equally  applicable  to  aggregations  acrossother demographic bins or activities. Similarly, our focus onideology  results in  a  US-oriented  analysis, as  the  Condordataset only provides ideology-relevant PPA assessments forUS users. While a clear limitation of this work, it does hintat the need for broader perspectives on how such left/rightscales can be generalized to other national contexts, as dis-cussed  in  Lo,  Proksch,  and  Gschwend  (2014).  Ultimatelythough,  teams  internal  to  Facebook  would  have  to  extendthe Condor dataset to include page-affinity scores for non-US audiences. Regarding ethics in research, this work and the Condordataset more generally has some considerations worth not-ing. Condor’s privacy protections provide value in prevent-ing identification of individual users’ actions on the platformbut at the cost of obfuscating rare phenomena. Vulnerableand minority groups who might be over-represented in theserare instances are potentially disproportionately impacted bythese protections, as researchers balance preserving privacy with  studying  how  behaviors  on  the  platform  may  impactthese groups. More work is needed to assess how platforms like Facebook interact with these populations and how wemight  study  these  interactions  while  still  providing  a  reasonable level of protection for these users.While we claim no conflicts of interest, for transparency, we note that one of the authors of this work has receivedfunding  from  Facebook  related  to  the  Social  Science  Oneinitiative.  This  funding  was  not  for  this  work,  and  while Facebook has had the opportunity to review this work priorto publication as part of the Social Science One agreement, they do not have authority to prevent publication. Finally, this work was reviewed by university internal review boardsas a prerequisite for gaining access to the Condor dataset."
RTANet: Recommendation Target-Aware Network Embedding,"Qimeng Cao, Qing Yin, Yunya Song, Zhihua Wang, Yujun Chen, Richard Yi Da Xu, Xian Yang",N/A,N/A
Recipe Networks and the Principles of Healthy Food on the Web,"Charalampos Chelmis, Bedirhan Gergin",Potential Impact and Ethical Considerations,"This work  presents  the first large–scale study  of online recipes healthiness using  a network–based approach.  To generate the two recipe networks we leverage a dataset of recipes sourced  from  Allrecipes.com,  the potential limitations of which are discussed in detail in (Chelmis and Gergin2022). To the best of our knowledge, the authors of (Chelmisand  Gergin  2022)  complied  with  the  terms  of  use  of  All-recipes.com while crawling the dataset. The dataset itself is licensed under the Apache License 2.0. It is worth mentioning that the main findings of this study are strongly restricted by this recipe collection. Therefore, generalizations should be avoided, unless the findings are reproduced with recipes sourced from other websites (e.g., epicurious.com or sim-plyrecipes.com) or datasets, such as the Recipe1M dataset(Marin et al. 2019).Finally,  this  study  neither  implements  nor empirically evaluates recipe substitution as a method for healthier food recommendations. However, by demonstrating the existence of a healthiness and rating paradox, our study paves the way for future work in this area by suggesting that given a recipe, similar, yet healthier recipes can be found using the network of recipes. A thorough evaluation of algorithmic solutions to recipe substitutions is necessary. From a user perspective, there is much to be learnt regarding user perception of recipe substitution compared with ingredient substitution, and how either approach relates to their health, dietary restrictions, or other constraints"
Partisan US News Media Representations of Syrian Refugees,"Keyu Chen, Marzieh Babaeianjelodar, Yiwen Shi, Kamila Janmohamed, Rupak Sarkar, Ingmar Weber, Thomas Davidson, Munmun De Choudhury, Jonathan Huang, Shweta Yadav, Ashiqur KhudaBukhsh, Chris T Bauch, Preslav Nakov, Orestis Papakyriakopoulos, Koustuv Saha, Kaveh Khoshnood, Navin Kumar",Discussion: Implications of Findings and Limitations,"Our RQ was to explore the broad differences between partisan news outlets in regard to Syrian refugees. A strength of our work is how the different techniques we have applied validate each other. For example, the sentiment and offensive speech scores over time detail possibly unfavorable representations of refugees in right-leaning media.  Similarly,  our  polarization and  question answering results both indicated that the left-leaning media tended to represent refugees as child victims, welcome in the US, and right-leaning media cast refugees as Islamic terrorists. The concordance in our results suggests the veracity of our findings and we hope that results can add to research and policy around refugees  and  other  displaced  individuals.  Our evidence is supported by previous research. Past work indicated that left-leaning US media often casts refugees as victims or individuals who can someday contribute to the US, allowing people to sympathize with refugees (Bhatia and Jenks2018). Conversely, right-leaning media represents refugees as a  burden  or  threat  to  the  US  (Bhatia  and  Jenks  2018). However,  previous  work  does  not  explore  the  sheer range of media articles around Syrian refugees using NLP techniques. We expand on previous research, providing a media overview of Syrian refugee representations and contrasts between left- and right-leaning media. Our  findings  relied  on  the  validity  of data collected with our search terms. We used Media Cloud to search for all articles relevant to Syrian refugees, and our data contained text representative of refugee representations. We are thus confident in the comprehensiveness of our data. We note that the recall of the search string was not tested, and that there may be possible biases as we did not manage to scrape all URLs due to broken links. Our data may not be  generalizable  to  US  representations  around non-Syrian refugees.  In  future,  we  will  expand  our  study  to broader refugee communities.  We  were  not  able  to  obtain  read  or share counts, to control for news outlets that are more widely read compared to a small town newspaper. We were not able to distinguish between bias free publications and opinion/-commentary articles. The team was unable to conduct more fine-grained analysis, e.g. are there news outlets whose representation of  refugees  has  changed?  Future  research will incorporate such analysis. Findings may also not apply to other  related  events  that  are  also  heavily  politicized  (e.g.,migration from Mexico and Central American) or other contexts (e.g.,  the  experience  of  the  Syrian  Refugee  Crisis  in Europe). Future work will take a broader approach, incorporating other crises."
DiPPS: Differentially Private Propensity Scores for Bias Correction,"Liangwei Chen, Valentin Hartmann, Robert West",Broader impact and ethical considerations,"DiPPS allows data analysts to perform analyses on data that was previously inaccessible due to privacy concerns. This can help get insights into understudied domains. Even more importantly, DiPPS can prevent drawing wrong conclusions from datasets that suffer from participation bias. However, the privacy guarantees of DiPPS are based on differential privacy, for which the privacy parameter ε needs to be set. In order to fully understand the privacy implications of their data sharing, individuals must be educated on the meaning of ε. A malicious data collector might even promise to use a certain value for ε, but in the implementation choose a larger ε; or just send data without any privacy protection at all. This can be prevented by releasing the client code. The privacy properties only depend on the client code but are independent of the server, and hence the server code need not be accessible."
Getting Back on Track: Understanding COVID-19 Impact on Urban Mobility and Segregation with Location Service Data,"Lin Chen, Fengli Xu, Qianyue Hao, Pan Hui, Yong Li",Ethics Statement,"The  mobility  data  from  Safegraph  are  aggregated  to  the CBG  level  on  a  monthly  basis,  and  thus  do  not  contain any individual-level data. To further enhance privacy, differential privacy techniques (https://docs.safegraph.com/docs/monthly-patterns\#privacy) are applied, and groups with too few visitors are removed. The demographic data from American Community  Survey  are  publicly  available  at  https://www.census.gov/programs-surveys/acs/, which also reports data on the CBG level. Therefore, no approval from the Institutional Review Board was required by the authors’ institutions."
What Are You Anxious About? Examining Subjects of Anxiety during the COVID-19 Pandemic,"Lucia L. Chen, Steven R. Wilson, Sophie Lohmann, Daniela V. Negraia",N/A,N/A
Analyzing the Engagement of Social Relationships during Life Event Shocks in Social Media,"Minje Choi, David Jurgens, Daniel M. Romero",Ethical Statement,"We describe the possible ethical concerns of our study and our efforts to mitigate them. First, the data collection was performed while abiding by Twitter’s Terms of Service on data collection and distribution,4, where we only used tweets publicly available from the API at the time the study was conducted. Second, due to the sensitive nature of the events described by the users and Twitter’s API terms of service, we will not make raw tweets publicly available. For reproducibility purposes, we will instead publish the Tweet IDs and  our  code.  Third,  we  do  not  report  findings  that  may compromise any individual’s privacy. Our results represent the aggregated behavior of hundreds or thousands of users . Fourth, our study is purely observational and we did not interfere, experiment, or interact with any user. Instead, the results of the paper were obtained through carefully designed quasi-causal methods.  In  summary,  our  findings  were obtained and presented while minimizing privacy risks and ethical concerns through several measures."
"Same Words, Different Meanings: Semantic Polarization in Broadcast Media Language Forecasts Polarity in Online Public Discourse","Xiaohan Ding, Michael Horning, Eugenia H. Rho",Ethics Statement,No personal information of Twitter users was collected nor compromised throughout our project. All data in this work are securely stored on servers only accessible by the authors. Our semantic polarization framework is made publicly avail-able on the authors’ GitHub page and can be applied on a variety of  textual  corpora  with  diachronic  and  contrastive properties.
Catch Me If You Can: Deceiving Stance Detection and Geotagging Models to Protect Privacy of Individuals on Twitter,"Dilara Dogan, Bahadir Altun, Muhammed Said Zengin, Mucahid Kutlu, Tamer Elsayed",Ethical Discussion,"The  primary  objective  of  our  research  is  to investigate methods that  could  potentially  mitigate  the  negative consequences of AI models, which can easily be weaponized against individuals. However, as weapons, the same AI models can be utilized for harmful purposes such as surveillance of individuals, or conversely, for benevolent purposes such as preventing the dissemination of misinformation and hate speech. Therefore, individuals who spread misinformation or hate can also use similar techniques to evade AI models that might detect their toxic messages. On the other hand, our methods will also be helpful for individuals who just do not  want  to  be  tracked  by  people  they  even  do  not  know. Using  the  analogy  of  AI  models  being  weapons,  our approaches can be considered armors that can protect against these models. We firmly believe that there should be available armors  in  the  market  if  we  know  that  there  are people with weapons. Our study makes a modest step toward this goal. We anticipate that our work will inspire other researchers to work on this important research direction and will develop more effective solutions than ours."
We Are in This Together: Quantifying Community Subjective Wellbeing and Resilience,"MeiXing Dong, Ruixuan Sun, Laura Biester, Rada Mihalcea",Broader Impact,"Our work, in conjunction with existing work (Ashokkumarand Pennebaker 2021; Biester et al. 2021), shows that the pandemic  had  different  effects  on  different  communities. Further, we show that signals from social media can be predictive of how a community copes with adversity. We found that cities more affected by the pandemic tended to have less connected members and had previously placed more importance on life aspects that were most impacted by social distancing during the pandemic, such as seeing friends and participating in group activities. Our features were predictive of whether a city’s wellbeing was affected by the pandemic. However,  predicting  the  subsequent  recovery  trajectory  of affected  cities  proved  to  be  more  difficult,  implying  that there are other factors involved and further work is needed to understand community resilience over time. Our findings indicate that differential policies should be put in place for communities, based on the pandemic’s local impact. Cities more impacted by social distancing measures may need to place higher priority on re-establishing social activities, such as local events and cultural festivals. Furthermore, policymakers could use automatically derived signals from social media as a real-time source of feedback for their policies, especially during times that require quick decision-making like during the pandemic. However, it’s important that such factors are considered holistically. A limitation of our findings is that they do not necessarily reflect the general public. Our work focuses on a single social media site (Reddit) where the users tend to be young (7) and male (8). Further, Reddit activity may potentially overrepresent the number of people affected by the pandemic (e.g., more people joining and posting due to physical lockdowns) or  exclude  those  who  largely  ignored  the  pandemic.  Our analyses look  at all posts  and  do  not  focus  only  on  posts that relate to COVID-19, which may lessen this bias. Additionally, there are many other facets of how communities acted during COVID, such as their general compliance with COVID-19 prevention measures or vaccination rates. However, further studies using other social media, surveys, and more facets of how communities acted during COVID (e.g., mask adherence, general compliance with COVID-19 prevention measures) can help support and extend our insights. Because our study is based solely on observational data, we  cannot  establish  causal  links  between  the  community characteristics we have identified and the wellbeing recovery outcomes. To address this, future work could involve col-lecting ground truth data about city recovery and resilience, such as through large surveys of individuals in each city regarding their wellbeing during the pandemic. Finally, our study should not be construed to be a comprehensive study of wellbeing. Subjective wellbeing does not consist solely of the presence of positive affect. It is more complex and multi-faceted, involving other aspects such as life satisfaction which are impacted in different ways (Ket-tlewell et al. 2020). Future work could study how community factors relate to these additional aspects of wellbeing. Furthermore, the relation of our wellbeing metric to metrics such as self-reported life satisfaction has not been studied; a misalignment between stance expressed in social media and public opinion surveys has been noted in prior work (Josephet  al.  2021),  and  we  leave  it  to  future  work  to  study  how wellbeing as expressed in social media posts relates to self-reported wellbeing."
Non-polar Opposites: Analyzing the Relationship between Echo Chambers and Hostile Intergroup Interactions on Reddit,"Alexandros Efstratiou, Jeremy Blackburn, Tristan Caulfield, Gianluca Stringhini, Savvas Zannettou, Emiliano De Cristofaro",N/A,N/A
Misleading Repurposing on Twitter,"Tuğrulcan Elmas, Rebekah Overdorf, Karl Aberer",Ethical Impact,"Data  Collection  and  Management: This  study  only  uses public  data  provided  by  Twitter  and  the  Internet  Archive, both of which have been analyzed extensively by previous work. To comply with the Twitter Terms of Service and protect the privacy of Twitter users, we do not share the data of repurposed accounts from the popular dataset. However, we share the ids of the repurposed accounts from the integrity dataset, since these accounts have already been made public by Twitter and, as such, there is no risk of further harms in their release. Threats to User Anonymity and PrivacyWe additionally mitigate any privacy loss to normal Twitter users by limiting our study to only two types of accounts: 1) accounts in the civic integrity dataset which have been designated by Twitter as harmful to public dialogue and released by Twitter, and 2) popular accounts which can influence the public. For an account to be considered “popular”, we follow Twitter’s lead in choosing a threshold of 5,000 followers, the threshold Twitter uses in the civic integrity dataset to determine if a user’s profile be made public. This group of accounts does include legitimate users who do not intend to mislead others or participate in malicious activity, and in the course of our study, we  uncovered  their  former  account  names/old  profiles via parsing publicly available data. This may include accidental deanonymization of a currently pseudonymized account if the user self-stated their identity in an old version of their profile  and  posted  enough  tweets  from  the  old  version  of their account to appear in the 1% sample. We mitigated this risk to the best of our availability by not releasing the data publicly, performing the annotation ourselves to not expose the data to crowd workers, and not reading their tweets. Further Potential Impacts of WorkWe must also consider the impact of publishing such a study and making this type of platform manipulation known to the general public and academic community. First, we hope that this work raises awareness among Twitter users that accounts that they follow may be repurposed for malicious purposes so that they can  notice  such  accounts  when  they  see  them,  and possibly even report them as malicious. We also hope that pointing out and studying this phenomenon urges academics and Twitter alike to put more resources into mitigation methods that do not have negative impacts on normal users, especially those from already marginalized groups. Awareness goes both ways, though, and this paper could also lead to malicious users learning about repurposing. This could lead to some who did not know that repurposing was possible to maliciously repurpose more accounts. However, we know from the widespread use of malicious repurposing that this phenomenon is already known by many who wish to use it maliciously. By bringing this problem to light, we hope to mitigate this risk by promoting user and platform awareness, thus discouraging its use. Although the goal of this paper is to uncover malicious re-purposing, parts of our methodology could be repurposed to deanonymize users who want to remain anonymous, as long as at one point in the past their account had an identifiable attribute. Users should be made aware that if they wish to remain anonymous, a new account should be created from scratch rather than repurposing a non-anonymous account. Finally, this work further illustrates that deletion privacy is important for users, but that it also can prevent malicious activity from being discovered. While users need to be able to  delete  and  hide  their  prior  activities  and  accounts,  this study underlines how such mechanisms can be misused to mislead and deceive users."
Scope of Pre-trained Language Models for Detecting Conflicting Health Information,"Joseph Gatto, Madhusudan Basak, Sarah Masud Preum",Ethical Impact,"This research involved human subjects only for data annotation, review, and prompt-based synthetic data generation. The project did not provide any intervention to any human subjects nor did it collect any user level data. So there is no risk to human subjects. The Amazon mechanical turk workers were recruited only for prompt-based synthetic data generation using formal procedures and no personal data was collected from them. The authors took careful measures to avoid annotation errors and maintain the quality and reliability of  the  data.  Future  progressions  of  HCD  studies,  to provide contextualized user-centric health information may require end-user medical data. This might raise various ethical and privacy concerns and will require careful consideration in the future. The collected advice statements are often for the general population. Thus, the HCD dataset may not contain many advice statements directed at underrepresented populations. Future  data  collection  rounds  should  focus  on diversifying both  medical  condition  coverage  and  target  audience. User-generated  medical  content  from  social  media  can  be a good source to collect health advice targeted to a specific sub-population, e.g.heart disease-related advice targeted to African Americans."
Author as Character and Narrator: Deconstructing Personal Narratives from the r/AmITheAsshole Reddit Community,"Salvatore Giorgi, Ke Zhao, Alexander H. Feng, Lara J. Martin",Broader Perspective and Ethical Concerns,"While the methods in this paper are evaluated on a single data set, r/AmITheAsshole, we believe the general concept of separating the author-as-narrator from the author-as-character is potentially useful across several domains. From a computa-tional perspective, those working in narrative understanding or character extraction could build on the methods here (Bam-man, O’Connor, and Smith 2013; Jahan and Finlayson 2019). From a social science perspective, political scientists and those working in media communications could be interested in disambiguating the author in the context of narrative per-suasion (Braddock and Dillard 2016) or how narratives shape public opinion (a situation comparable to asking “who is the asshole?”) (Card et al. 2016). There are always several ethical concerns when working with public social media data. While r/AmITheAsshole subreddit is a public forum where users request moral judgments from their online peers, it is important to note that the Redditors have not consented to any research studies. Indeed, this problem is not particular to r/AmITheAsshole and is part of a larger issue of using publicly available social media data in research. While focused on mental health applications, Chancellor, Baumer, and De Choudhury (2019) consider who is the “human” in machine learning research that uses social media data and discuss a number of implications around informed consent. As such, to preserve anonymity, all results are reported in aggregate, and we do not report direct quotes. Also of note is the fact that we use age and gender to classify moral judgments, including a very narrow (binary)definition of gender. We do not intend to imply that any given age or gender is or should be considered an “asshole.”"
Google the Gatekeeper: How Search Components Affect Clicks and Attention,"Jeffrey Gleason, Desheng Hu, Ronald E. Robertson, Christo Wilson",Ethical Statement,"In accordance with our IRB-approved experimental protocol, we obtained informed consent from participants before collecting any data, participants were compensated for installing our  extension,  and  we  informed  participants  that they could uninstall our extension at any time. Our extension automatically uninstalled itself at the end of the data collection period. Given that the focus of this study is on the behavior of search engines, not users, we do not anticipate any adverse impact on participants. We protect participants’ privacy by not sharing any of their individualized data. After publication we will release the aggregated data and source code to reproduce the figures in the paper."
Understanding and Detecting Hateful Content Using Contrastive Learning,"Felipe González-Pizarro, Savvas Zannettou",N/A,N/A
SciLander: Mapping the Scientific News Landscape,"Maurício Gruppi, Panayiotis Smeros, Sibel Adalı, Carlos Castillo, Karl Aberer",Ethics Statement,"Our  work  aims  at  finding  representations  that  capture the similarities and  differences  between  news  sources  in their coverage of the COVID-19 pandemic. Our proposed method bases this  representation  on  the  language  usage, content copy/sharing  behavior,  and  their  stance  towards scientific references. We show that the representations learned from these signals  are  useful  for  several  downstream  tasks, including understanding the reliability of a source. This is accomplished by  using  proxies  to  trust  scientific  references, language, and content. One must be careful when applying this method to untested dimensions, such as the presence oflanguage usage by minority groups. These groups may be underrepresented in the training data, which may cause the model to make biased predictions about them. We propose that this method aids the decision-making process as a complement to human judgment rather than a replacement."
A Data Fusion Framework for Multi-Domain Morality Learning,"Siyi Guo, Negar Mokhberian, Kristina Lerman",Ethical Statement,"Morality  is  relatively  personal  and  subjective.  It  can  vary based on different individuals, backgrounds or cultures. In this study,  we  focus  on  English  language,  American culture, and the morality expressed in news articles or on social media platforms. Unfortunately, in the datasets or the pre-trained models that we have used, it is possible that biases exist with respect to gender, race, or other factors."
Representing and Determining Argumentative Relevance in Online Discussions: A General Approach,"Zhen Guo, Munindar P. Singh",Broader Impact and Ethical Use,"Information  overload  on  social  media,  which  contains repeated, noisy, and uninformative content, reduces people’s efficiency in knowledge acquisition. This work contributes to argument-mining  tasks  such  as  mining  coherent arguments and assessing the completeness and effectiveness of an argumentative discussion. Potential privacy and ethical concerns do not arise directly from this research but may from its potential applications. Although our dataset is anonymous and does not trace user-related information such as user names or historical posts, the  proposed  approach  may  help  pinpoint  impactful  postsand  influential  users.  Besides,  for  such  text  mining  where the content is public on social media, there is a possibility that the owner of a comment may be traced by searching the content online. We have obtained proper consent from data providers and human annotators for this study."
The Morbid Realities of Social Media: An Investigation into the Narratives Shared by the Deceased Victims of COVID-19,"Hussam Habib, Rishab Nithyanand",Ethical considerations,"Conducting this study was a challenging task, largely owing to the questionable ethics of the dataset being studied and the communities that curated them. In fact, there has been much media attention and criticism showered on  these  communities  for  the  unempathetic  discourse surrounding the victims of Covid-19 — even spilling over to public conflicts between the moderators of the communities (Judkis  2022). We  undertook this  work  from  the perspective that the victims cataloged by these communities were ultimately failed by our political climate, leaders, and the platforms they relied on. This paper is meant to highlight these failures so they may not repeat. With regards to operational ethical considerations, our study did not scrape posts from non-public domains and did not violate the scraping limitations set by any platform/website. Whenever available, we relied on an official API for data gathering and analysis. Finally, our dataset of screenshot of posts does not include any personally identifiable information. The names and pictures of the posters (unless the poster is a public figure) were made illegible by the curators."
Motif-Based Exploratory Data Analysis for State-Backed Platform Manipulation on Twitter,"Khuzaima Hameed, Rob Johnston, Brent Younce, Minh Tang, Alyson Wilson",Ethical Statement,"On a small scale, this paper will advance the study of state-sponsored influence online. More broadly, our work aims to help institutions analyze SBPM online to mitigate its influence. There are already efforts to understand and mitigate SBPM  on  social  media,  because  of  its  detrimental  effects on societies around the globe (Zannettou et al. 2019). Any method that contributes to this effort promotes authentic discourse online. Twitter users agree to allow their data to be made publicly available when signing the terms of service. Twitter’s algorithm for selecting data is not publicly known, so any biases in their algorithm may manifest in models trained on Twitter data. We intentionally develop and analyze a variety of datasets in an effort to have a better representation of the Twitter population. This research could be used in both the public and private sectors to allow the development of more adaptive policies that address SBPM. Our approach is intended as a screening method, not as a standalone method, to help identify potential state-sponsored influence, and we believe it is most effectively incorporated into a system to avoid misidentification and false positives."
Happenstance: Utilizing Semantic Search to Track Russian State Media Narratives about the Russo-Ukrainian War on Reddit,"Hans W. A. Hanley, Deepak Kumar, Zakir Durumeric",Ethical Considerations,"We utilize only public data and follow ethical guidelines as outlined by others (Hanley, Kumar, and Durumeric 2022). We do not deanonymize users in our Reddit dataset, and our data collection does not breach the platform’s terms of service. We recognize that Russo-Ukrainian War is an ongoing conflict and a humanitarian crisis. Sensitivity to the topic is paramount.  We  hope  that  our  work  provides  objective  in-sight into the information campaigns surrounding the war."
"""A Special Operation"": A Quantitative Approach to Dissecting and Comparing Different Media Ecosystems’ Coverage of the Russo-Ukrainian War","Hans W. A. Hanley, Deepak Kumar, Zakir Durumeric",Ethical Considerations,"Within this work, we utilize public data and follow ethical guidelines as outlined by others (Hanley, Kumar, and Durumeric 2022). We do not seek to deanonymize users within our Weibo and Twitter datasets. We recognize that Russo-Ukrainian War is an ongoing conflict and that information about the war is changing day to day. We hope to remain objective and sensitive about the issues discussed here"
The Geography of Facebook Groups in the United States,"Amac Herdagdelen, Lada Adamic, Bogdan State",Ethics Statement,"While  the  research  was  carried  out,  the  authors  were either employees or contractors of Meta Inc., the owner of the Facebook social networking platform, which also provided the funding and resources for this work. The principal benefit of the data and analysis is uniquely rich insight into the deeper structures of social capital, especially as they unfold on increasingly-important online platforms. As detailed in the literature review, social capital is a crucial factor for the health of local communities. The most important risk identified relates to breaches of user privacy. To minimize this risk we (1) look at user location information coarsened to the county level and (2) aggregate all computed indicators across all groups local to a county. No individual-level data was used in the study and the dataset is limited to counties with at least 100 users contributing to the aggregates. The authors confirm having read the AAAI Code of Ethics and Conduct and their commitment to abide by it."
Quotatives Indicate Decline in Objectivity in U.S. Political News,"Tiancheng Hu, Manoel Horta Ribeiro, Robert West, Andreas Spitz",Ethical Statement,"This  work  uses  publicly  available  data  to  analyze quotes from U.S. politicians to study media bias. We match politicians’ names between Quotebank and Wikidata. Our study utilizes one identity characteristic – the political party of the involved speakers – at an aggregated level in order to investigate the effect of ideology in quotative usage. We do not perform any individual-level inferences. Additionally, we manually validate  both  speaker  disambiguation  and quotative extraction methods to minimize the risk of identifying the wrong individuals and ensure the veracity of our findings. Given that politicians are public figures and the importance of research to better understand the language used in political journalism and its implications, we believe that our work is in line with reasonable expectations of privacy (Doherty 2007). We do not foresee potential negative societal impacts coming from this research. On the contrary, we believe that a better understanding of our political media ecosystem is essential to improve it. We confirm that we have read and abide by the AAAI code of conduct."
Information Retention in the Multi-Platform Sharing of Science,"Sohyeon Hwang, Emoke-Agnes Horvat, Daniel M. Romero",Ethics Statement,"A  serious  consideration  for  the  presentation  of  any quantitative measure is how it may incorporate biases or black boxes of complex human concepts. As a difficult construct to quantify, information retention is a par excellence example of this, as noted in our discussion of the validation survey. In order to prevent our proposed quantification from becoming misapplied, we selected the most scrutable version of it, such that interpretation and limitations of what the measures suggest are clear. This simplicity also helps undermine unreasonable extrapolations in arguments about the quality of information retention of content when applied beyond this work. Additionally, research utilizing posts from sites containing content from individuals, such as social media and/or blog users, who may not be aware that their content is used for  research  also  encounter  important  concerns  about  the integrity  of  users’  privacy.  In  our  work,  we  consider  only public-facing content accessible by any arbitrary individual. In addition, we only use posts that were still available and not  deleted  by  the  users  at  the  time  of  our  study.  Finally, our results describe user behavior only in aggregate and at a scale that leaves individual posts unidentifiable. While minimizing potential risks, the expected benefits of our contributions to the understanding of information retention in the diffusion of scientific findings across platforms are substantial and foundational for a better appreciation of intentional and unintentional information distortion online. Our findings not only point to general patterns of information  retention  that  might  inform  media  strategies,  such as deliberate dissemination across multiple channels, but also are generative in raising potential mechanisms for improving the  fidelity  of  information  in  online  discussions  to be tested and examined for causality in future studies."
Measuring Belief Dynamics on Twitter,Joshua Introne,Broader Impacts and Ethical Considerations ,"An important goal of this work is to advance ongoing research about how media, misinformation, and design might influence belief dynamics. I have demonstrated the method using a narrow set of data from a single platform, but it is relatively straightforward to  adapt  the  approach  to  other text-based forms of social media (e.g., Reddit, Facebook) and to examine the fluctuation of dynamics in relation to different circumstances. This is one of the more impactful applications of the Belief Landscape Framework. There are many cross-disciplinary discussions  about  the role  media and misinformation play in polarization and the  sustenance (or even amplification of) exclusionary belief structures but untangling the causal forces at play is  complex. The    BLF could shed new light on these causal interactions by revealing the impact of numerous factors (e.g., a single fake news article or a coordinated media campaign) on be-lief dynamics. Methods such as surveys, sentiment analysis, or stance detection offer a similar kind of insight, but with less precision. A  refined version of the BLF would be unprecedented in the granularity of insight it affords and speed with which it can detect changes in belief dynamics. The  BLF raises  many  important  ethical  questions. The method  might  be improved to  make  accurate  predictions about how different forms of media exposure influence, for instance,  the  dynamics  of  anti-vax or  racist  beliefs.  This could  be  used to  develop more  effective interventions  to move beliefs in either direction. There is already concern about how algorithms intended to shape engagement with online content may have unintentional side effects on belief and social dynamics. The technology envisioned here could be used to manipulate belief intentionally, and it is therefore urgent that, as a society, we begin to develop regulatory and legal frameworks to grapple with this. It is critical that the research community has  an active role in such discussions. It is also important to consider individual privacy and autonomy. In this paper, I have sought to protect individual’s anonymity by editing quoted tweets, but more advanced versions of this work will need to address other challenges. For instance, a method like this could be used to make predictions about  specific  individuals,  e.g.,  whether  someone  is likely to become a skeptic, fall for misinformation, or join an extremist network. It is therefore important to consider the ethical implications of predictive applications.  Such concerns should not prevent further pursuit of these methods, because they can help us better understand how media  and  technology  influence  belief  dynamics. Rather, pursuing this inquiry in dialog with a research community that values the social good is one of the better ways to minimize the likelihood they will be used to do harm."
Lady and the Tramp Nextdoor: Online Manifestations of Real-World Inequalities in the Nextdoor Social Network,"Waleed Iqbal, Vahid Ghafouri, Gareth Tyson, Guillermo Suarez-Tangil, Ignacio Castro",Ethical Statement,"This research study has been approved by the Institutional Review Board (IRB) at the researchers’ institution. The authors have no competing interests or funding that could undermine this research. We employ users’ public post records from Nextdoor to study their conversations. Nextdoor data is public, as there is the expectation that strangers can view the posts (Townsend  and  Wallace  2016).  Upon  collection, we anonymize the data before use and store it in a secure silo. Toprevent user identification, we aggregate our data and analyse at a neighborhood level. After aggregation, we discard any user-level information. Our work does not share or re-distribute Nextdoor content, as per Nextdoor’s Terms of Service. Importantly, web crawling is legal for non-commercial research in the UK (IPO 2021) and the USA (TechCrunch 2022), where the data collection is performed. From a broader perspective, our analysis demonstrates that predicting the income of users based on their online discourse is feasible.  We believe this finding is an important contribution, particularly as this might further enable algorithmic surveillance (Zuboff 2015) by making easier to segment users based on their economic circumstances."
Weakly Supervised Learning for Analyzing Political Campaigns on Facebook,"Tunazzina Islam, Shamik Roy, Dan Goldwasser",Ethical Impact,The data collected in the paper was made publicly available by Facebook Ads API and does not contain any personal in-formation. Any qualitative result that we report is an outcome from a machine learning model that does not represent the authors’ personal views.
Online Emotions during the Storming of the U.S. Capitol: Evidence from the Social Media Network Parler,"Johannes Jakubik, Michael Vossing, Nicolas Prollochs, Dominik Bar, Stefan Feuerriegel",Ethics Statement,We respect the privacy and agency of all people potentially impacted  by  this  work  and  take  specific  steps  to protect their privacy  (see  main  text).  The  analysis  was  conducted in accordance with the Institutional Review Board at ETHZurich.
Effect of Feedback on Drug Consumption Disclosures on Social Media,"Hitkul Jangra, Rajiv Shah, Ponnurangam Kumaraguru",Implications and Ethical Considerations,"All subreddits involved in our work list harm reduction as one of the community’s primary goals. We believe our models and  findings  have  direct  implications  for community moderators and platform designers involved in harm reduction interventions. Feedback based: One of our key insights is increased drug consumption activity by users who received positive community feedback.  Thus  communities  can  experiment with different strategies of showing feedback, like only showing counts, partial, or rate limited feedback and quantify the reduction in said effect. Our insight and models can also help design  community  feedback  guidelines  regarding limiting community interactions on specific activities. Intervention  based: User’s  feedback  history  combined with our proposed deep learning classifier can help in monitoring drug consumption activity at an user or cohort level. High-risk individual(s) can be detected, and timely interventions like notifying, community reach outs, or restricted activity can help in reducing overall self-harm. Some interventions may also have adverse effects; hence, more  experimentation  is  required  before  moving  forward. We acknowledge that tracking user data and restricting platform usage patterns can violate privacy and freedom of expression. However, our work does not aim at providing specific intervention  methods.  Instead,  we  provide necessary insights, data, and models that researchers and community moderators can use for further work based on every community’s rules and ethics. Resource based: A variety of research can be conducted on these  platforms  to  understand  and  prevent  the harms caused by drug consumption. However, the validity of any such work  is  dependent  on  ensuring  that  the  online content provides a strong proxy for offline drug consumption. We open-source a manually annotated dataset and our pre-trained models from drug consumption classification to enable further research."
SexWEs: Domain-Aware Word Embeddings via Cross-Lingual Semantic Specialisation for Chinese Sexism Detection in Social Media,"Aiqi Jiang, Arkaitz Zubiaga",Ethical Considerations,"Online  sexism  and  abuse  are  sensitive  subjects  with various ethical concerns in the controversy surrounding the freedom of speech. To develop the fairness and reliability of our work, we address the following limitations: Confidentiality: Accessing the data is essential to make our work effective. Since the data is already public, to address the trade-off between privacy and effectiveness, original data has all personally identifiable data removed to ensure user anonymity. Potential for harm: Our work is not intended to harm vulnerable groups who are already discriminated against. While one could make bad use of sexism detection systems, such as learning to circumvent detection of their posts, our work is solely intended for the benign purposes of detection and mitigation of sexist speech. Results communication: Our work is free of plagiarism or research misconduct, but acknowledge potential limitations when analysing social media data, especially sex-ist data that does not clearly represent the attack target."
Retweet-BERT: Political Leaning Detection Using Language Features and Information Diffusion on Social Networks,"Julie Jiang, Xiang Ren, Emilio Ferrara",Ethical Statement,"We believe our work has the potential to be used in combating misinformation and conspiracy spread, as well as identifying communication patterns between and within polarized communities. However, we are aware of the ways our work can be misused. For instance, malicious actors can use our work to politically target certain groups of users and propagate the spread of misinformation. As such, we encourage researchers to use these tools in a way that is beneficial for society. Further, to protect the privacy of the users and also in accordance with Twitter’s data sharing policy, we will not be sharing our actual dataset, nor the partisan labels, but only the Tweet IDs used in this paper through the original dataset release papers (Chen, Lerman, and Ferrara 2020; Chen, Deb, and Ferrara 2021). All data used in this paper are public and registered as IRB-exempt by the University Southern California IRB (approved protocol UP-17-00610)."
"Images, Emotions, and Credibility: Effect of Emotional Facial Expressions on Perceptions of News Content Bias and Source Credibility in Social Media","Alireza Karduni, Ryan Wesslen, Douglas Markant, Wenwen Dou",Broader Perspective and Ethics,"This study was conducted in experimental settings. The procedures of the study were approved by our institution’s IRB, every participant signed an informed consent, and throughout  the  study,  the  participant’s  identities  remained anonymous. We believe our results could potentially be used by malicious actors to further influence consumers’ judgments. However,  as  most  social  media  interactions  are  driven by polarized outrage (Rathje, Van Bavel, and van der Linden2021), these results can engage the community in an ethical discourse on the curation of sensationalized visual media by mainstream and misinformation organizations. Moreover,  to  learn  about  the  true  impacts  of  content  on  users’ beliefs and attitudes, we believe that results of experimental settings should be repeated “in the wild” (Mosleh, Penny-cook, and Rand 2022). Such in-the-wild experiments, however, require attention to both platform rules (in our case, Twitter), and ethical guidelines for interacting with users on social media. These ethical questions for social media experiments are critical, as it is difficult to maintain anonymity on these platforms. In the future, as we move towards combat-ing harmful information on social media, such ethical considerations become truly essential."
InfluencerRank: Discovering Effective Influencers via Graph Convolutional Attentive Recurrent Neural Networks,"Seungbae Kim, Jyun-Yu Jiang, Jinyoung Han, Wei Wang",Broader Impact and Ethical Considerations,"The utility of our proposed framework is expected to significantly increase given a decision of Instagram, one of the most popular influencer marketing platform, that considers to hide the number of likes on each post (Instagram 2021; Loren  2019)  to  help  mental  health  issues  of  social media users (Royal Society for Public Health 2017). Unlike prior work, the number of likes is not used in discovering influencers in InfluencerRank,  hence  our  proposed  model  can be  particularly  used  by  brands  with  relatively  small business sizes, who may be suffering from the heavy expense of discovering effective influencers among millions of candidates (Instagram 2017) in a situation where the number of likes is hidden from other users. Additionally, our model is also capable of adopting additional node features and node types in the network for further improvements. As a result, we  believe  our  model  can  be  widely  exploited  in finding highly effective influencers for businesses from small retailers to global brands."
Popular Support for Balancing Equity and Efficiency in Resource Allocation: A Case Study in Online Advertising to Increase Welfare Program Awareness,"Allison Koenecke, Eric Giannella, Robb Willer, Sharad Goel",Ethical Statement,"While our research aims to generate positive societal impact via increasing equity in SNAP enrollment, there remains a primary ethical consideration: in optimizing for SNAP enrollment among minority demographics, we inherently reduce the SNAP enrollment among majority demographics. Below, we discuss this trade-off and its potential societal impact, as well as concerns arising from data collection. For each  source  of  potential  negative  societal  impact,  we  describe the principles used to mitigate our concerns. The crux of our work involves setting a fixed budget for an advertising bidding algorithm, and optimizing for potential SNAP enrollees who are Spanish speakers. For each additional Spanish speaking individual presented with a Get-CalFresh  ad,  we  will  necessarily  decrease  the  number  of English speaking individuals presented with the same ad — potentially by more than one. The long term consequences of  our  experiment  include  that  certain  individuals belonging to majority groups will not be shown the GetCalFresh ad, and will thus have a lower likelihood of filling out Get-CalFresh’s SNAP application when searching for the same Google keywords that would otherwise trigger the GetCal-Fresh ad to be shown. Across California, we hope to see an increase in SNAP applications from individuals who would not otherwise have easily found the online resources to complete the forms, in keeping with GetCalFresh’s goal of assisting the neediest individuals. If applied broadly, our framework can be used to substantiate decision-makers’ choices across a range of algorithm-based applications. Depending on the individuals and groups whose preferences are surveyed, this could either yield policy suggestions that propose more equity-based allocations, or ones that propose more efficiency-based allocations as is the norm. The key distinction will stem from whose preferences are elicited, and whether their fairness preferences are biased outside the scope of the efficiency-equity trade-off. One way to ameliorate this concern is to ensure representation of underrepresented groups among individuals whose preferences are being elicited (Kasy and Abebe 2021; Whit-taker 2020). As  to  the  ethical  challenges  of  data  collection,  this research uses data on three fronts: first, from Google ad target-ing towards a large swath of Google users in California; second, from Code for America’s compilation of GetCalFreshapplications; and third, from our Prolific survey. In Google ad targeting, we do not have access to any individual-level data; rather, we can only see audience-level statistics (e.g., how many total impressions or clicks were received on an ad). In the GetCalFresh applications, Code for America continuously tracks all applications that come through its system,  but  takes  particular  care  to  ensure  data  privacy.  For example, even though one could argue the benefits of collecting race-based data from users to optimize for racial equity, the GetCalFresh application does not collect race data at all because the application does not require race information. Further, our team only obtained access to anonymized household-level data pertaining to the research at hand. In the Prolific survey, we pre-registered our experiment viaAsPredicted(#84866),  indicating  what  individual-level  data we aimed to collect; we made the decision to not publicly re-lease said data for Prolific user privacy reasons—our dataset includes sensitive  information  such  as  political  affiliationand income levels, which were imperative to collect to understand the socioeconomic drivers of fairness preferences. Across these three data sources, we have minimized the potential data privacy harm to the extent possible while still allowing for this research to be conducted. The survey question text,  along  with  code  reproducing  data  analysis,  are posted on GitHub for reproducibility. Across both the inherent demographic trade-off and data privacy considerations, we have made the choices we feel best  lead  to  equitable  outcomes  for  the  neediest  potential GetCalFresh users, with minimal harm to the broader set of potential users. While our research focuses on SNAP within California, there is room for future work both across America, and via analogous food stamp programs globally. However, our design choices would need to be revisited since the concept of neediest recipients may vary considerably in different contexts."
Personal History Affects Reference Points: A Case Study of Codeforces,"Takeshi Kurashima, Tomoharu Iwata, Tomu Tominaga, Shuhei Yamamoto, Hiroyuki Toda, Kazuhisa Takemura",Ethics Statement,"The findings of this study are intended to be used to assist people in continuously improving their skills. The only concern is that it might not always be good to encourage users of a site to be more active; excessive its use could be problematic. This should be kept in mind when using the results of this study. The  data  used  in  this  study  is  publicly  available  with Codeforces  users’  permission.  Because  we  only  used  the public data, we did not recruit any human subjects for this research. Anyone can access the open information, making it easy to reproduce our datasets."
Large-Scale Demographic Inference of Social Media Users in a Low-Resource Scenario,"Karim Lasri, Manuel Tonneau, Haaya Naushan, Niyati Malhotra, Ibrahim Farouq, Víctor Orozco-Olvera, Samuel Fraiberger",Ethical Statement,"Addressing the previously unknown, we describe NigerianTwitter and highlight that interpretable and fair algorithms can provide comparably high performance to more advanced but less  transparent  and  potentially  more  biased  methods. Broadly speaking, beyond describing Nigerian Twitter, we expect  that  the  utility  of  this  approach  will  be  evident  in future work that relies on demographic inference to evaluate policy impact. Yet, we acknowledge that our approach, as well as broader research aimed at inferring demographic attributes of users, may raise several ethical concerns. For instance, the tools developed can be used for profiling purposes in pursuit of malicious objectives. Due to the accessibility of available tools and the high risk of re-identification (Rocher, Hendrickx, and De Montjoye 2019), the data used for development and evaluation may be sensitive and require confidentiality. Moreover,  we  are  aware  that  name-based demographic inference may  disproportionately  miscategorize minority groups and  individuals  which  can  have  serious empirical and ethical consequences, as extensively discussed in Lock-hart, King, and Munsch (2023). In this work, we only provide a modeling pipeline aimed at accurately inferring demographic traits of social media users and thus remain agnostic on the usage of such tool. In doing so, we leave it to practitioners and researchers who wish to incorporate such information in their analysis to estimate whether their workis  ethically  desirable.  It  is  our  responsibility,  however,  to draw attention to a number of critical points and limitations, which should be taken into account when evaluating whether future work building on our methods is ethically justified. In the  following,  we  build  on  the  suggestions  formulated  by Lockhart, King, and Munsch (2023). First, our method produces attributes based on external ascriptions, and therefore should be used in case studies where one is interested in external ascription, e.g. how social media users perceive each other, instead of focusing on a user’s true sense of self-identity. Additionally, our method builds on labels produced and revised by local domain experts who have a strong knowledge of the extent to which names or profiles signal  certain  traits,  as  described  in  §3.3.  Labels assigned without such precaution might not be as accurate and produce erroneous inferences. We try to limit subjective judgments and individual biases in the annotation processby duplicating the labeling task among our four experts and by making sure disagreements are arbitrated. This however does not impede unfair biases being shared by all of our an-notators, despite their level of expertise. Further, for each demographic attribute, we limit ourselves to traits which can be retrieved from a user’s name with high accuracy in a given population, as demonstrated by our name matching results. In doing so, we fail to capture a variety of subgroups, including non-binary individuals, ethnic minorities, and traditional faiths, as resources are lacking for these groups which could result in developing poorly performing models. This draws a limitation of our approach: while providing accurate predictions at the aggregated level, it disregards minority sub-groups, which limits inclusivity. Any downstream usage of methods or data similar to ours should take this limitation into account. Finally, as our pipeline is accurate at an aggregated level, downstream applications relying on similar data should preferably make use of demographic predictions at the group level, as individual predictions might contain erroneous associations which could add confounds to the modeling pipeline."
Associative Inference Can Increase People’s Susceptibility to Misinformation,"Sian Lee, Haeseung Seo, Dongwon Lee, Aiping Xiong",Ethical Statement,"We have taken careful steps to ensure research ethics. First, we worked with our institutional review board (IRB) office and obtained their approval before running the online experiments. Second, implied consent was obtained for each participant before all experiments. Third, the study presented little to no risk compared to those encountered in people’s everyday  online  activities.  Moreover,  the  results  from our study can benefit researchers and practitioners to build better tools to mitigate misinformation from human aspects. We believe the benefit outweighs the potential risk."
Beyond Discrete Genres: Mapping News Items onto a Multidimensional Framework of Genre Cues,"Zilin Lin, Kasper Welbers, Susan Vermeer, Damian Trilling",Ethical Statement,"For this study, we did not process any personal or otherwise sensitive data; we also did not in any way manipulate or mislead any human participant. Neither did we build a system that leads to biases disadvantaging minority groups or similar. On the contrary, our work could be beneficial to similar tasks in relevant disciplines, and our code could be easily ap-plied by others. We expect no potential negative outcomes of these usages."
"""Learn the Facts about COVID-19"": Analyzing the Use of Warning Labels on TikTok Videos","Chen Ling, Krishna P. Gummadi, Savvas Zannettou",N/A,N/A
Improving Mental Health Classifier Generalization with Pre-diagnosis Data,"Yujian Liu, Laura Biester, Rada Mihalcea",Ethical Statement,"While the users in our training set all shared their depression diagnosis on a public online forum, we acknowledge that special care should be taken with such data considering the sensitivity of the subject. As has been done in prior studies,  we  removed  identifiers  such  as  Reddit  usernames from  our  personal  copy  of  the  data,  and  make  no  attempt to ascertain any information about the users who compriseour dataset beyond what is written in their Reddit posts. The study that resulted in the Twitter dataset received full IRB approval  from  our  institution;  personal  identifiers  such  as Twitter usernames were scrubbed from the dataset. Ethics around health-related social media data are explored in more detail in Benton, Coppersmith, and Dredze (2017).In our work, we show one method that improves generalizability of depression diagnosis classifiers (with simpler models) to a population of people who may not explicitly discuss mental health. While our method improves upon the baseline, the results do not suggest that such a model is ready  for  real-world  deployment.  The  task  of detecting depression from  text  is  very  challenging,  and  our  resultson out-of-domain data that is collected without using self-reported  diagnoses  show  that  we  still  have  a  long  way  to go with respect to accuracy on populations that differ from those that we see in our training data (regardless of how that data is sampled). However,  the  more  important  question  to  ask  may  behow  such  a  classification  system  should  be used if accuracy reaches  an  acceptable threshold and how to  define that threshold for various potential applications. A very accurate depression  classification  system  could  be  used  for good:  monitoring  population-level  depression  (e.g.,  Wolo-han (2020)), routing counselors to those with the most need in resource-constrained  settings  (e.g., as recommended  by Bantilan et al. (2020)), opt-in prompts to receive counsel-ing on college campuses if classifiers see symptoms devel-oping, or opt-in monitoring for people who are already receiving counseling. However, the same systems could also be used for nefarious purposes, such as denying jobs to people whose mental health status is inferred from their social media posts. This would be illegal in the United States, but it may  not  be  in  all  countries,  and  an  action  being  illegal does  not  eliminate  the  risk  of  it  occurring.  While  out-of-scope for this paper, the question of how mental health classifiers should be used and which classification setups will most  benefit  society  while  reducing  harm  should  be considered more thoroughly by the community, with active involvement from mental health practitioners. To the best of our knowledge, these considerations have been understudied in the NLP community; the few exceptions that focus on the ethical tensions surrounding mental health classifiers have appeared outside of NLP (Chancellor et al. 2019). We hope that the community will consider and participate in inner-disciplinary work that directly considers how mental health classification models can be deployed; one recent example of such work is Cohen et al. (2020)"
Team Resilience under Shock: An Empirical Analysis of GitHub Repositories during Early COVID-19 Pandemic,"Xuan Lu, Wei Ai, Yixin Wang, Qiaozhu Mei",Ethical Statement,"Results from this analysis could help organizations and individuals to understand the resilience of remote teams under shock and could potentially help them make decisions about remote work post-pandemic and on a longer horizon. Data used in this study are from third-party platforms (i.e., GHArchive and GHTorrent). We do not collect or release a new dataset. During data processing, we do not violate ethical principles or attempt to link the identities of developers."
Contextualizing Online Conversational Networks,"Thomas Magelinski, Kathleen M. Carley",Broader Perspectives and Ethics,"Contextualizing  data  allows  for  more  accurate representation of user’s importance within a discussion. Social media analysis can have high stakes when it is used to determine the importance, or presence, of users within information operations. While this work moves closer to properly attributing users to the conversations that they are actually active in, there is a question of interpretability. The move towards deep graph neural networks makes interpretability challenging. While the initial layer of our model is easy to interpret, this  becomes  more  challenging  as  layers  are  stacked.  We have  tried  to  validate  that  our  model  is  appropriately representing the data by checking even the intermediate node representations of hashtags and URLs, but if this work is to be applied to qualitative work looking to attribute accounts a high-stakes setting, much more in-depth checks about how specific users fit into a conversation must be taken."
Comfort Foods and Community Connectedness: Investigating Diet Change during COVID-19 Using YouTube Videos on Twitter,"Yelena Mejova, Lydia Manikonda",Broader Impact,"The broader aim of this work is to contribute to the understanding of  health  behaviors  using  user  generated  content and computational tools, specifically, the insights and tools we present here apply to a broad spectrum of stakeholders. First and foremost, the research design of this study attempts to minimize any harm to the users whose content was captured in this research, as their usernames and other identifiable information was excluded from the report and the analysis. Still, various high-risk groups could be captured here, such as minors (despite the platforms trying to enforce age restrictions), those struggling with eating disorders, or lacking access to healthy and affordable food. Secondly, there is a large portion of users who may have been affected by this content who have seen or interacted with it, without being captured by our data collection process. Those not captured would  also  include  those  with  disabilities,  and who were unable  to  use  these  platforms  due  to  lack  of  access. Furthermore, findings here may impact the decision-making of public health researchers, both in terms of insights into information sharing behavior during COVID-19, and in terms of the scope of the available technology for monitoring such behavior.  As  such,  we  are  aware  that  tools  for  public social media data surveillance may be misused in order to target people or engage in other kinds of surveillance – note that such behavior would be against the Terms of Service both Twitter (Twitter 2022) and YouTube (YouTube 2022). Still, in an effort to provide transparency in the research, we will make the dataset available in accordance with the above Terms of Service, and along with the manual and automatic annotations necessary for the analysis."
Authority without Care: Moral Values behind the Mask Mandate Response,"Yelena Mejova, Kyriaki Kalimeri, Gianmarco De Francisci Morales",Ethical Statement,"The dataset presented here contains only tweets which were publicly available at the time of the collection. We make the dataset publicly available to the research community in compliance with the Twitter Terms of Service,24that is, sharing only the tweet IDs of the collected posts, which will have to be re-collected. In this paper, we have rephrased all quoted tweets to prevent re-identification of their authors. This practice ensures that the tweets which have been removed (either by the user or the platform) will not be available. Although large, this dataset does not include users with particular disabilities which may disallow them to interact with the platform, as well as minors and those blocked by Twitter. On the other hand, the content collected here affects not only those who have posted it, but also those who viewed or interacted with it, which may be orders of magnitude more users, since most users are “lurkers” who consume social media content without posting (Van Mierlo 2014). Ultimately, the masking decisions made by people engaging in this deliberation may directly affect the health and life of vulnerable people, such as those with autoimmune disorders or other conditions making them especially vulnerable to COVID-19. Additionally, the sometimes aggressive rhetoric in this material may not be suitable for young Twitter users, or those dealing with mental health issues. Also, although the focus of this study is the moral dimension of the debate, we caution public health communicators not to overemphasize moral or emotional dimensions of their message (or attempt to emotionally manipulate their audience), but rather provide the clearest and most informative messaging possible. Further, we would like to discourage the tools used in this study to be used for targeting individuals espousing particular opinions for harassment or undue surveillance, and to follow the AAAI ethical guidelines (25) in the application of these findings."
Bridging Nations: Quantifying the Role of Multilinguals in Communication on Social Media,"Julia Mendelsohn, Sayan Ghosh, David Jurgens, Ceren Budak",Broader Impact,"Understanding the role of multilinguals in information diffusion has  immense  consequences.  Platforms  like  Twitter can empower multilinguals to spread information that supports positive outcomes such as knowledge-sharing, collaboration, crisis response, or social progress, thus enabling different language communities to benefit from a truly global social network (Eleta and Golbeck 2014; Hale 2014a). Our study  not  only  highlights  this  potential  but  also identifies how it varies across topics and with respect to the geographical, linguistic, and political relationship between the countries. For instance, our research suggests that multilinguals can  be  better  utilized  to  spread  political  news  as opposed to entertainment. We also see that their importance is more pronounced for supporting information spread across countries further away from each other. Such findings not only highlight the contexts where multilinguals already play an important role but also help us identify the barriers for cross-lingual diffusion; in such situations, platforms may benefit more from technologies such as machine translation. Our research can also help platforms address dangerous consequences of  global  networks  by  focusing  efforts  on nudging multilinguals to mitigate the spread of harmful information such  as  misinformation,  conspiracy  theories,  or online abuse. Past network science research shows the value of betweenness centrality in identifying nodes that can limit the spread  of  such  information  (Golovchenko,  Hartmann ,and  Adler-Nissen  2018).  Here,  we  show  that  multilingual nodes  tend  to  have  high  betweenness  centrality.  Furthermore, our study shows that multilinguals play a particularly important role in the spread of political topics, common targets for malicious actors aiming to spread propaganda and disinformation. Despite the potential for positive impact, we acknowledge the ethical risks of this work. Rather than stem the flow of harmful content, our work may inspire malicious agents to target and  manipulate  multilinguals  into  propagating  such information.  In  addition,  our  focus  on  users  of  politically and  socially-dominant  language  varieties  and  use  of  automated language detection excludes people whose posts contain endangered or minority languages, non-prestige dialects of dominant languages, or code-mixing. Although our work does not present direct harm to individuals, these decisions systematically exclude  marginalized  groups  whose online behavior deserves equal consideration.To  promote  transparency  and  future  research,  we publicly share data, code, and models but take steps to preserve user privacy. The datasheets shared for causal effect estimation include only variables necessary to replicate our results. We  do  not  share  user  IDs,  raw  text,  or  other  personally-identifiable  information.  While  the  location  inference  tool used presents a privacy risk by inferring users’ specific geo-coordinates, we only store information at the country level."
Information Operations in Turkey: Manufacturing Resilience with Free Twitter Accounts,"Maya Merhi, Sarah Rajtmajer, Dongwon Lee",Ethics,"This  work  provides  novel  and  valuable  insights  to  the research community  studying  IO  and  coordinated influence online. We provide our dataset of a suspected live Turkish IO on Twitter, along with our random sample of Turkish-language  Twitter  users  used  to  train  our  classifier.  Both datasets are available on the first author’s Github page (15). Following Twitter’s Terms of Service, we release only the User ID’s and Tweet ID’s for all data presented here (16). Also following Twitter’s protocols, we suppress the usernames of all users with fewer than 5000 followers. In  this  work,  we  also  obtained  and  analyzed  Twitter’sunhashed versions of their archived IO data. Academic researchers must  apply  for  access  to  the  unhashed  versions of  the  data,  provide  details  on  the  proposed  usage, analysis, storage of the data, and sharing of results obtained from analyzing the data, and sign a data agreement. The first author obtained access to the unhashed data, and followed all guidelines laid out by Twitter. We  expect  that  these  datasets  may  be  utilized  to build models to detect future Turkish IO as their strategies continue to evolve. We acknowledge that some users in our live collected dataset may not be affiliated with the Turkish state and may not be attempting to influence online users through coordinated operations. We present the live dataset as suspected IO based on our observations and analyses, but we cannot assess the origins and intentions of these users with certainty  given  the  information  we  have.  This  is  true  for Twitter’s archive data as well, which Twitter acknowledges as do we, and which motives the suppression of usernames for users with fewer than 5000 followers. Both datasets were collected by the first author through their personal  Twitter  account  using  the  Academic  TrackTwitter  API  and  stored  on  a  password  protected external hard drive. The data were also uploaded to a cloud server for analysis, which is protected with two-factor authentication. After analysis, data were removed from the cloud server and stored only on the password protected external hard drive."
"""This Is Fake News"": Characterizing the Spontaneous Debunking from Twitter Users to COVID-19 False Information","Kunihiro Miyazaki, Takayuki Uchiba, Kenji Tanaka, Jisun An, Haewoon Kwak, Kazutoshi Sasahara",Ethical Statement,"We pay the utmost attention to the privacy of individuals in this study.  We  did  not  include  personal  names  or account names in our analysis. Moreover, in the example figures, we blur user identity-related features (name, photo, and user id)to maintain  anonymity. Lastly,  for sharing  our tweet  data, we will publish only a list of tweet IDs, without any text or information, according to Twitter’s guidelines."
Echo Tunnels: Polarized News Sharing Online Runs Narrow but Deep,"Lillio Mok, Michael Inzlicht, Ashton Anderson",Ethics Statement,"Because of the political nature of our work, we recognize the need to protect the privacy of users engaged with partisan content on the platform. We used publicly available, pseudonymous Reddit data from PushShift, through which individuals may  request  to  delete  their  Reddit  histories  at any time. In addition, we used additional measures to protect user privacy: our study presents only aggregated results, does not identify nor analyze individual histories, and stored data in  a  secure  server to  which  only  members of our research team had access."
The Chance of Winning Election Impacts on Social Media Strategy,"Taichi Murayama, Akira Matsui, Kunihiro Miyazaki, Yasuko Matsubara, Yasushi Sakurai",Ethical Considerations,"The  data  in  this  paper  is  derived  from publicly accessible user-generated content.  We  pay  the  utmost  attention  to the privacy of individuals in this study. When sharing our twitter data, we will publish only a list of tweet IDs."
BotBuster: Multi-Platform Bot Detection Using a Mixture of Experts,"Lynnette Hui Xian Ng, Kathleen M. Carley",Ethical Considerations,"Social bot detection through automated means bring about a key ethical consideration: accuracy,  transparency  and  robustness  of  a  social  bot detection algorithm collectively forms a “devil’s triangle” (Thieltges, Schmidt, and Hegelich 2016). Accuracy is paramount as misclassification can lead to the deplatforming of legitimate social media users. At the same time, a positive bot classification does not indicate a malicious account users should further discern the account characteristics to be sure to weed out malicious accounts only. To enable wider usage, the algorithm should be transparent. However, an increase in algorithm transparency provides bot operators information to adapt bot account characteristics to evade detection, increasing the variation of bot characteristics. The alteration of bot behavior based on the knowledge of the bot detection algorithm creates a drop in the robustness and accuracy of the algorithm in the detection of new and evolved bot accounts. Bot detection is a cat-and-mouse game; transparency must be balanced with robustness (Fazzolari et al. 2020). All three pillars must be balanced because excessive focus on any of them can give the reign of social media space to malicious bot operators."
"""Dummy Grandpa, Do You Know Anything?"": Identifying and Characterizing Ad Hominem Fallacy Usage in the Wild","Utkarsh Patel, Animesh Mukherjee, Mainack Mondal",Ethical Statement,"In this work, we collected and analyzed data from CreateDebate  and  also  conducted  an  annotation  survey  for validating our classifier. However, since we were analyzing user-generated  data  in  this  work,  we  tried  our  best  to conduct our study ethically and protect the privacy of the users in our dataset. Specifically, we leveraged the previous work byEysenbach and Till (2001) to check the ethics of our work. We noted that CreateDebate is a moderate-sized forum witharound15k members, and no registration was necessary to view  and  collect  the  CreateDebate  data,  signifying  it  was an ‘open’ forum. Finally, the debate topics often revolved around general  phenomena  (e.g.,  election),  signifying the potentially public nature of our collected dataset. Nonetheless, following the footsteps of previous work by  Cook, Ay-ers, and Horsch (2018), we hashed usernames after data collection to protect the privacy of the users during our analysis. Along the same lines of ethical consideration, for our annotation study, we did not collect any personally identifiable data from our participants to protect their privacy."
On the Relation between Opinion Change and Information Consumption on Reddit,"Flavio Petruzzellis, Francesco Bonchi, Gianmarco De Francisci Morales, Corrado Monti",Ethical Impact,"As researchers working with user-generated data, our first consideration must be devoted to evaluating whether the data we used in this work was properly collected and treated. In this study, Reddit users that authored any content we used were in general aware of the public nature and accessibility of their content: the communities under study are in fact in the public domain, visible without any account or password, and have thousands of participants. We highlight that we did not recover any content willingly deleted by its author. Furthermore, no personally identifiable information was ever collected: Reddit users make use of pseudonyms, and the messages employed in this study involve only one’s view on general, broad topics, making it difficult to uncover any participant’s identity. Finally, all the data was used and presented only as aggregated estimates. Further considerations must tentatively evaluate the potential broader impact of our work. Among positive outcomes, identifying the relationship between opinion change, polarization and online information consumption patterns can advance our understanding of how dis- and misinformation sources can be picked up by social media users, and help design public information campaigns. Of course, however, the same knowledge can also be used to leverage opinion change events in order to spread disinformation. Subsequently, any ethical judgement on possible applications of our work on information spreading ultimately depends on a value of merit on the information being spread. However, we believe that understanding how do we change our opinion online and how this affects our information diet helps in different ways. On the one hand, it recognizes the importance that one’s views have on the external world; on the other hand, it furthers our comprehension of how we might fall victims of propaganda."
This Sample Seems to Be Good Enough! Assessing Coverage and Temporal Reliability of Twitter’s Academic API,"Jürgen Pfeffer, Angelina Mooseder, Jana Lasser, Luca Hammer, Oliver Stritzel, David Garcia",Ethics Statement,"Our research was not subject to the Ethics Commission at the Technical University of Munich, where the experiments were conducted. Only public Twitter data were used and the publicly available APIs were used. We were not interested in Personal Identifiable Information (PII) in this study and none of the analyses was performed on the individual account level. For those experiments in which we have sent Tweets, we only created Tweets with a single random 42-character  string  to  minimize  the  risk  that  our  Tweets will manipulate the data collection of other researchers. With this study, we have violated Twitter’sTerms of Service, in particular, the following section: ”You may not do any of the following [...] (ii) probe, scan, or test the vulnerability of any system or network ...” However, we strongly believe that our work, as well as similar work, is important to better understand the data that are used by thousands of researchers and practitioners. More transparency about the data will  lead  to  higher  quality  and  more  trustworthy research, which in turn, will also be an added value for Twitter."
The Geometry of Misinformation: Embedding Twitter Networks of Users Who Spread Fake News in Geometrical Opinion Spaces,"Pedro Ramaciotti Morales, Manon Berriche, Jean-Philippe Cointet",Ethics Statement,"Our  analyses  were  performed  on  pseudonymized  data.  AData  Management  Plan  was  filled  with  our  university’s Data  Protection  Officer  as  required  by  GDPR  regulation, and  a  Potential  Risks  Analysis  report  was  also  filled to further assess  the  implications  of  our  dataset.  The  related Legal  Notice  and  additional  documents  can  be  found  athttps://medialab.sciencespo.fr/en/activities/epo/.Our  study  leverages  political  opinions  of  users,  and  we have taken all necessary steps described in GDPR to work with, and manage separate pseudonymized data to limit the risks associated  with  sensitive  information.  Working with these data provides a crucial advantage as it allowed us to unveil previously-unobserved socio-political dynamics underlying fake  news,  opening  new  paths  to  understanding, monitoring, and managing this phenomenon."
Spillover of Antisocial Behavior from Fringe Platforms: The Unintended Consequences of Community Banning,"Giuseppe Russo, Luca Verginer, Manoel Horta Ribeiro, Giona Casiraghi",Ethics Statement,"A positive outcome of our research is that it can help mainstream platforms design policies to mitigate the spillover of anti-social behavior. For example, a platform might introduce automatic labeling of communities similar to banned ones, allowing users to make more informed decisions about their participation. However, our findings may also be used to justify turning a blind eye to problematic communities, citing spillover concerns. For example, a platform might tolerate abusive behavior in isolated communities rather than risk the spillover of that behavior to the wider platform following a ban. We primarily use publicly available data that does not require user consent. We collect data from the fringe platforms because it is an integral part of this research. We do not  use  any  personally  identifiable  information  (PII) from the dataset, and we do not make any inferences about individual users. Similarly, we do not name any other subreddits or users associated with the banned communities. We confirm that we have read and abide by the AAAI code of conduct"
Cross-Lingual and Cross-Domain Crisis Classification for Low-Resource Scenarios,"Cinthia Sanchez, Hernan Sarmiento, Andres Abeliuk, Jorge Perez, Barbara Poblete",Ethical Statement,"We use existing social network data, clearly indicating the source and  respecting  the  policies  on  data  sharing and anonymity. Our overarching goal is to expand crisis informatics applications  to  low-resource  languages.  However, there exist inequalities in access to the Internet, especially prevalent in low-income countries. These geographical and socio-demographic  biases  are  present  in  the  source  of  the data and create important challenges for crisis informatics."
How Much User Context Do We Need? Privacy by Design in Mental Health NLP Applications,"Ramit Sawhney, Atula Neerkaje, Ivan Habernal, Lucie Flek",Broader Impact & Ethical Considerations,"Emphasizing the sensitive nature of this work, we acknowledge the  trade-off  between  privacy  and  effectiveness.  To avoid coercion and intrusive treatment, we work within the purview of acceptable privacy practices suggested by Chancellor et al. (2019). We paraphrase all examples shown in this work using the moderate disguise scheme (Bruckman 2002) to protect user privacy (Chancellor et al. 2019). We utilize publicly available data in a purely observational (Norval and Henderson 2017), and non-intrusive manner. For all tasks, we specifically only use existing datasets, and all user data is kept separately on protected servers linked to the raw text and network data only through anonymous IDs.We acknowledge that suicidality is subjective, the interpretation of this analysis may vary across individuals on social media (Puschman 2017), and we do not know the true intentions of the user behind the post. Care should be taken so as to not to create stigma, and interventions must hence be carefully planned by consulting relevant stakeholders, such as  clinicians,  designers,  and  researchers  (Chancellor  et  al. 2016). We acknowledge that suicide risk exists on a diverse spectrum (Bryan and Rudd 2006), and a binary distinction is a task simplification intended to alert the human in the loop about exceeding a possible intervention threshold. We note that the studied data is limited to English-speaking Twitter, and also recognize that the data may be susceptible to other demographic, annotator, and medium-specific biases (Hovyand  Spruit  2016).  Although  our  work  attempts  to analyze aspects of users’ nuanced and complex experiences, we acknowledge the limitations and potential misrepresentations that can occur when researchers analyze social media data, particularly data from a group to which the researchers do not explicitly belong. We acknowledge that it is almost impossible to prevent abuse of  released  technology  even  when  developed  withgood  intentions  (Hovy  and  Spruit  2016).  Hence,  we  en-sure  that  this  analysis  is  shared  only  selectively  and subject to IRB approval (Zimmer 2009) to avoid misuse such as Samaritan’s Radar (Hsin, Torous, and Roberts 2016). Moreover, we aim to strive for an informed public, by addressing the dual-use threat with preemptive disclosure accompanying the code, in line with Solaiman et al. (2019). Our work does not make any diagnostic claims related to suicide. Our models and analysis should form part of a distributed human-in-the-loop system for finer interpretation of risk."
Effects of Algorithmic Trend Promotion: Evidence from Coordinated Campaigns in Twitter’s Trending Topics,"Joseph Schlessinger, Kiran Garimella, Maurice Jakesch, Dean Eckles",Ethics Statement,"The paper contributes to understanding of practical, ethical, and policy aspects of algorithmic recommendation. Our paper provides concrete, data driven evidence to build the case for a debate on trending topics. As we saw from our results, the effects of trending might be short lived but depending on the case, they might be impactful. As with the two cases used in our analysis, Twitter trends have been widely manipulated and artificially manipulated trends happen all the time. There have  been  numerous  calls  to  disable  trending  topics, due to posited harms and their susceptibility to manipulation (9). In many cases, the manipulation of trending topics is readily detectable and can be fixed easily, though perhaps such campaigns would effectively adapt in response to such efforts. The Indian WhatsApp campaigns are easily detectable based on their repetitive content (Jakesch et al. 2021). With the Turkish ephemeral trend attacks, Twitter could simply account for  deleted  tweets  in  the  trending  algorithm  (Elmas  et  al.  2021).  In  October  2020,  in  preparation  for  the 2020  US  election,  Twitter  started  adding  more  context to their trending topics just for users in the United States, thus manually curating trending topics. Compared with the U.S., where trends are at most rarely astroturfed, astroturfed trend-ing topics are apparently more common in the Global South, in countries such as Nigeria, India, and Brazil. This can reflect a pattern of U.S. tech companies neglecting less lucrative foreign markets. This paper contributes evidence about the prevalence and consequences of trending topics, which could feature in arguments for greater effort ensuring the integrity of trending topics or removing that feature where they cannot."
Detecting Anti-vaccine Users on Twitter,"Matheus Schmitz, Goran Muric, Keith Burghardt","Broader Perspective, Ethics and CompetingInterests","The AVAXTAR system has the potential to positively impact our understanding of what leads to vaccine hesitancy. Conversely,  the  same  ability  of  identifying  anti-vaccine users could be leveraged to more perverse goals such as discrimination or targeted attacks. It is a socially tenuous line between incentivizing  the  population  based  on  the  vast research backing  up  vaccination  and  coercing  or excluding persons given their stance on vaccination. Any efforts to define an “in-group” and an “out-group” can run the risk of further social division. For this reason, we make no judgement on whether a user with a probability score of, e.g., 0.6 or0.99, is anti-vaccine or not. These probabilities should only be taken  at  face  value.  Lastly,  we  recognize  that machine learning models can sometimes make wildly incorrect predictions, especially for edge cases. It is necessary to devise guardrails when building applications on top of AVAXTAR. The main benefit of AVAXTAR is that it enables future scientific research as well as development of applied solutions to  the  current  challenge  of  vaccine  hesitancy.  Maximizing this positive impact demands free and open access to AVAXTAR. Such a publishing approach has to be weighted against the costs of possibly enabling the more perverse usages of our work. After significant consideration, we regard the risks of AVAXTAR being used to single out individuals to an extend that would be materially harmful to them as very  unlikely.  Moreover,  if  such  aims  are  present, the malicious actor, who is supposedly willing to expend significant resources in its attack, can always replicate a similar system  (Yuan,  Schuchard,  and  Crooks  2019;  Carrieri, Lagravinese, and Resce 2021; Huang et al. 2017; Lincolnet al. 2022; Wang, Yin, and Argyris 2020). Conversely, we see the  muffling of  AVAXTAR technology as  a hindrance to  an  entire  community  working  towards  ameliorating  the side-effects of social media, such that limiting AVAXTAR’savailability should cause more harm via preventing development on this area than it would prevent via curbing potential malicious use. Thus we convene that a public and freely dis-tributed AVAXTAR is the preferable choice with regards to ethics"
Cybersecurity Misinformation Detection on Social Media: Case Studies on Phishing Reports and Zoom’s Threat,"Mohit Singhal, Nihal Kumarswamy, Shreyasi Kinhekar, Shirin Nilizadeh",Ethical Considerations and Broader Impact,"We  analyzed  publicly  available  data,  provided  by  Twitter Streaming API and Crowdtangle API. We also follow standard ethical guidelines (Rivers and Lewis 2014), not making any attempts to track users across sites or deanonymize them. We believe that our results show that misinformation about cybersecurity and privacy exists, and we hope that the community can further investigate its impact on the user and can research solutions to tackle this challenge."
Characterizing and Identifying Socially Shared Self-Descriptions in Product Reviews,"Lu Sun, F. Maxwell Harper, Chia-Jung Lee, Vanessa Murdock, Barbara Poblete",Ethics Statement,"This study shows that reviewers willingly and publicly disclose a wide variety of personal information. This information is  in  general  non-identifying  and  intended  to  provide a  practical  service  in  relation  to  an  opinion  about  a product. On their own, self-descriptions in reviews do not necessarily pose a privacy concern. Furthermore, self-descriptive information in reviews can be a noninvasive way of understanding customers, according to what they themselves are comfortable sharing. However, the aggregation of multiple self-descriptive reviews at  individual  level  could  potentially  lead  to unintended disclosure of identifying data. We believe that privacy breaches in this manner, although highly unlikely, are not impossible. On one hand, this type of analysis is based on data which users voluntarily make public. Hence, reviewers have  the  choice  to  select  what  information  they deem sensitive or not. On the other hand, self-descriptive information is quite sparse in review data, therefore providing useful information at product level aggregation, but very little information at individual level aggregation. Nevertheless, our recommendation, which is in alignment with how  this study was conducted,  is to avoid  user level information aggregation and focus on product level aggregation.  This  is,  if  reviewer  level  aggregation  is  discouraged, the risk of privacy breaches almost disappears, as self-descriptive information will then only remain associated to reviews and not to reviewers themselves"
Social Influence-Maximizing Group Recommendation,"Yangke Sun, Bogdan Cautis, Silviu Maniu",Ethics and Competing Interests,"The positive outcome of our research is more effective recommendations, leading to more awareness and adoption of items. In our view, there are no negative outcomes and no ethical implications pertaining to the data collection process."
Top-Down Influence? Predicting CEO Personality and Risk Impact from Speech Transcripts,"Kilian Theil, Dirk Hovy, Heiner Stuckenschmidt",Ethical Statement,"In  the  following,  we  discuss  possible  biases  and environmental considerations. Social  Desirability  Bias: Past  literature  has  shown that some Big  5  personalities  are  more  socially  desirable than others,  which  paves  the  way  to  discrimination:  Overall, it is socially desirable to score low on neuroticism (an omitted scale in the MBTI) and high on conscientiousness and agreeableness. To a lesser extent, it is socially desirable to score high on extraversion and openness (Ones, Viswesvaran, and Reiss 1996, Table 2). For the MBTI, in contrast, there existno “bad” personality traits. As shown in Figure 3, however, the Big 5 and the  MBTI correlate moderately to  strongly. Therefore, the points raised about social desirability, albeit to a lesser extent, should apply here, too. Sample  Biases: Critically,  our  gold  standard  consists of just 32 CEOs of large American (mostly tech) companies. While  these  companies  (Alphabet,  Facebook,  Apple,  etc.) constitute  a  large  share  of  the  American  market,  this renders the personality prediction model less applicable to non-American,  small,  or  non-tech  companies.  Only  four  (i.e.,12.5%) of the 32 CEOs are female. While this gender ratio is twice as high as that of the S&P 500 (Catalyst 2021), this highlights that the findings of this study might generalize poorly to non-male CEOs. In addition, as shown in §, Figure 2, CEOs as a social cohort share a distinct distribution of personality traits, which is why we argue that the MBTIregressors should only be applied with caution, if at all, to non-executive samples. Energy Consumption: Training  neural  models  can  have  substantial  financial  and environmental   costs   (Strubell,   Ganesh,   and   McCallum 2019), which motivates us to discuss the computational efficiency of the Transformers. Using an NVIDIA Tesla P100GPU, we run a hyperparameter optimization over 40 configurations per MBTI dimension for both BERT and RoBERTa.The average power consumption is 200W and the optimization takes ca. 16 hours, i.e., 3.2 kilowatt hours (kWh) with an electricity cost of 40 cents per model.10Labeling the 22Kearnings call instances with no available ground truth takes ca. 4.5 hours and 140W, i.e., 0.63 kWH of GPU time and 8cents, respectively. Training time of the SVM with trigram tf–idf is negligible (ca. 2 minutes on a quad-core processor with 8GB RAM). Whether the performance increases of the Transformers over a sparse method justify the added computational costs should be considered carefully on a case-by-case basis"
Identifying Influential Brokers on Social Media from Social Network Structure,"Sho Tsugawa, Kohei Watabe",N/A,N/A
A Multi-Task Model for Sentiment Aided Stance Detection of Climate Change Tweets,"Apoorva Upadhyaya, Marco Fisichella, Wolfgang Nejdl",Ethical Statement,"The data in this paper comes from publicly available user-generated online content. Although we focus on identifying the attitude of a tweet based on the tweet text rather than individual user characteristics, such data poses risks for targeting the authors of the tweets and problems with their privacy. To mitigate these issues and comply with the terms of use, we are committed to protecting individual privacy and therefore avoid sharing personally identifiable content. The dataset that is made publicly available consists only of tweet IDs and annotations."
An Open-Source Cultural Consensus Approach to Name-Based Gender Classification,"Ian Van Buskirk, Aaron Clauset, Daniel B. Larremore",Impact Statement,"A  crucial  aim  of  our  work  is  to  make  the  application  of name-based gender classification in scientific research more ethical and robust. We achieve this in four ways. We leverage a  computational  framework  that  acknowledges  name-gender associations as products of a fluid cultural consensus rather than fixed features of individuals. We explicitly explore limitations and document when they may impact analysis. We scope our method to use in prosocial scientific research which stands in direct contrast to existing methods used in  applications  such  as  targeted  advertising.  Finally, we provide a rigorous conceptual framework for reconciling name-based gender classification with more general concerns and gender theory. The risk of misuse persists, but our thorough analysis and careful documentation makes it clear how and when this method is appropriate to use and what it reflects about the individuals classified. Since our name-based gender classification method is directly descendent  of  the  name-gender  association  data  we collected,  the  same  considerations  apply  to  its  release.  In fact, the open-source nature of our data and method ensures that researchers can make even more informed decisions of when it is appropriate to apply our method. Additionally, the community can build on this data to make further improvements to how classification is done in practice. Finally,  care  was  taken  in  collecting  and  releasing data to protect the privacy of individuals and respect the sources from which data was collected. Save for one, all data sources used were already publicly available. We’ve held this IRBprotected data out of our release and created a synthetic version that matches on aggregate features for use in replicating results."
Reddit in the Time of COVID,"Veniamin Veselovsky, Ashton Anderson","Conclusion, Broader Impacts, and EthicalConcerns","This work acts as an empirical foundation for future analyses of  social  media.  We  focused  on  the  “what  changed” question; we believe that this is a necessary precursor to the next set of analyses on “why” they changed. In particular, we report a series of interesting, and sometimes surprising, changes that we experienced over the course of COVID-19. Additionally, our approach is general so it can be used in future analyses to study Reddit in times of calm and change. There  are  a  couple  of  possible  ethical  concerns  in our study that we attempt to mitigate. To begin, the Pushift Red-dit dump potentially contains deleted comments and posts. But given our aggregated analysis, these harms are minimal. Additionally, no authors were paid or associated with Red-dit during the course of the analysis limiting any potential conflicts of interest. With  social  media  occupying  an  increasingly important role in our lives, it is becoming more important than ever to study and audit these platforms and how they change, since understanding them will help us understand ourselves. We believe that the methodology and framework we propose are general enough  that  they  can  be  applied  to  different platforms during times of crisis and calm."
Identifying and Characterizing Behavioral Classes of Radicalization within the QAnon Conspiracy on Twitter,"Emily L. Wang, Luca Luceri, Francesco Pierri, Emilio Ferrara",Ethical Statement,"In this study, we do not identify individual users or provide exact quotes from users and present data in an aggregated manner in order to protect user privacy. For the same reason, we do not share the inferred political leanings or the list of persistent QAnon users. The Tweet IDs of data used in this paper can however be accessed via the original public dataset (Chen, Deb, and Ferrara 2022) in accordance with Twitter’s data-sharing policy. We caution applying our findings to censor users—content moderation against accounts should remain impartial and consistent with Twitter’s rules. Project approved by USC IRB (#UP-21-00005-AM001)."
AnnoBERT: Effectively Representing Multiple Annotators’ Label Choices to Improve Hate Speech Detection,"Wenjie Yin, Vibhor Agarwal, Aiqi Jiang, Arkaitz Zubiaga, Nishanth Sastry",Ethics Statement,"Hate speech online is a sensitive issue, and there are some ethical issues in the controversy on free speech. To further improve the fairness and reliability of our work, we claim the following ethical considerations: Confidentiality: Access to data is critical to the effectiveness of our work. Since the data is already publicly available, we have replaced all personal data with a special token <user> to ensure user anonymity. The information of all the annotators corresponding to the dataset is hidden, and only the ID number of the annotator and its annotation content is displayed. Potential for harm: We do not intend to harm vulnerable groups that  are  already  discriminated  against  based on specific characteristics. Our work serves only the benign purpose of detecting and mitigating abusive expressions. Results communication: We guarantee that there is no plagiarism or academic misconduct, but we acknowledge that there may be limitations and potential misrepresentations when analysing social media data, particularly for those abusive data that does not clearly represent the target of the attack. It  can  be  debatable  whether  all  annotator perspectives should be treated equally, especially when they lack knowledge or relevance to the speech at question. If annotators are random samples from the population, it is likely that they diverge from the opinions of the minority groups targeted by online  hate  speech.  In  an  extreme  scenario,  for example, treating a white supremacist annotator and an oppressed individual with the same weights can further suppress the voice of the latter group. Future work from a social science perspective is needed. Moreover, adversaries, who actually spread hate speech online, can use this kind of research for malicious purposes such as to learn how to prevent being detected."
Unique in What Sense? Heterogeneous Relationships between Multiple Types of Uniqueness and Popularity in Music,"Yulin Yu, Pui Yin Cheung, Yong-Yeol Ahn, Paramveer S. Dhillon",Ethics Statement,"The study was conducted on public data collected from various websites and Spotify API. We focus only on population-level  music  consumption  data.  Hence,  there  is  no violation of individual-level privacy. However, the music listeners might not expect their data to be accessed by others via Spo-tify’s API or scraped from the Internet."
Conversation Modeling to Predict Derailment,"Jiaqing Yuan, Munindar P. Singh",Ethical Impacts,"Our work proposes ways to model conversations and predict whether a conversation will develop into a personal attack. The datasets we work on contain only user IDs from Reddit and Wikipedia talk page, which do not reveal personal identities (though if a user has revealed their identity in some other post, it could be discovered). The proposed framework and trained model can be applied by social platforms to assist with content moderation, where early warnings can be issued to prevent personal attacks from happening. As with many other pretrained deep learning models, our model could be exploited by users so that they learn the pattern to avoid the censor. Our model could also be limited in its ability to accurately capture conversation dynamics as the domain and topics evolve over time. However, we posit that active and continual learning could help mitigate this problem."
Minority Stress Experienced by LGBTQ Online Communities during the COVID-19 Pandemic,"Yunhao Yuan, Gaurav Verma, Barbara Keller, Talayeh Aledavood",N/A,N/A
How Circadian Rhythms Extracted from Social Media Relate to Physical Activity and Sleep,"Ke Zhou, Marios Constantinides, Daniele Quercia, Sanja Scepanovic",N/A,N/A
Who Is behind a Trend? Temporal Analysis of Interactions among Trend Participants on Twitter,"John Ziegler, Michael Gertz",Ethics Statement,"Especially  relevant  to  this  work  are  ethical considerations in the context of the collected dataset, as well as a potential impact of results gained from studying actor networks behind trends. After all, mainly real users are behind trends and social media postings in general. Regarding the Twitter trend dataset as used in the present work, we picked a ”harmless” topic to collect tweets about, given in the form of the EURO2020 soccer championship. Note that in our results, we do not present any sensitive information and rely on aggregated statistics whenever possible. Our work aims at a better understanding of dynamic actor networks behind trends, and in the long run, with even more techniques and methods at hand, those insights could potentially be abused in a way that topics damaging to our societies are reinforced by malicious actors or that under-represented topics are obstructed during their emergence. We do not give any hint on how gathered insights could be abused but stick to sim-ply conducting observations. Driving for a good change, we argue that those insights might as well be or even should be used to detect undesired activities and to prevent those during their early stages."
Towards Generalization of Machine Learning Models: A Case Study of Arabic Sentiment Analysis,"Samir Abdaljalil, Shaimaa Hassanein, Hamdy Mubarak, Ahmed Abdelali",Ethics and Social Impact,"With this exploration, there are ethical and social considerations to keep in mind. User Privacy: To comply with Twitter Privacy Policy, we share the tweets by IDs, and ensure that the corresponding tweet texts as well as the user handles, are not shared. Biases: It is important to note that any biases in the proposed dataset were unintentional. Due to the random nature of data collection over the specified period of time, we understand that some countries and/or dialects could be represented with the data more than others. However, this could be due to the fact that Twitter usage in certain countries is much higher than that of other countries within the region. The same applies to the topics represented within the dataset, as we tried to minimize bias towards a certain topic by having a prolonged data collection time-frame between the years 2009 and 2020."
A Multi-Platform Collection of Social Media Posts about the 2022 U.S. Midterm Elections,"Rachith Aiyappa, Matthew R. DeVerna, Manita Pote, Bao Tran Truong, Wanying Zhao, David Axelrod, Aria Pessianzadeh, Zoher Kachwala, Munjung Kim, Ozgur Can Seckin, Minsuk Kim, Sunny Gandhi, Amrutha Manikonda, Francesco Pierri, Filippo Menczer, Kai-Cheng Yang",Ethical Statement,This  study  has  been  granted  exemption  from Institutional Review Board review (Indiana University protocol 17036). The collection and release of the dataset are in compliance with the platforms’ terms of service.
Wiki-Based Communities of Interest: Demographics and Outliers,"Hiba Arnaout, Simon Razniewski, Jeff Z. Pan",Ethical & FAIR Considerations,"In  this  work,  datasets  released  are  based  on  public information and  tools  provided  by  Wikimedia  projects.  We do not use any personal information. Every dataset record, i.e., JSON object, includes all equivalent labels and IDs of properties and items, retrieved from Wikidata (December 2022version). Users can refer to these IDs for more details and definitions."
#RoeOverturned: Twitter Dataset on the Abortion Rights Controversy,"Rong-Ching Chang, Ashwin Rao, Qiankun Zhong, Magdalena Wojcieszak, Kristina Lerman",Ethical Statement,"All of the data in this dataset is publicly available information. Our data collection was deemed exempt from review by the Institutional Review Board (IRB) at the University o fCalifornia-Davis and University of Southern California, as it relied solely on publicly available data. The data collection adheres to Twitter’s terms of service (Twitter 2022a). In compliance with Twitter’s terms and conditions, we only release the Tweet IDs of publicly available tweets and re-quire users of the dataset to comply with Twitter’s terms and conditions as well. There may be ethical concerns regarding user anonymity. Tweet  objects  contain  user  information.  Users  have the option to  restrict  their  tweets  from  being  made available through the  API  by  switching  to  a  private  account  or by deleting their tweets. In this article, we only present aggregated statistics to address this concern."
Tweets in Time of Conflict: A Public Dataset Tracking the Twitter Discourse on the War between Ukraine and Russia,"Emily Chen, Emilio Ferrara",Ethical Considerations,"As mentioned earlier in this paper, we are only able to publish the tweet IDs associated with our collected tweets as a part of our data collection. This is to ensure that we remain in compliance with Twitter’s developer terms of service, which restricts us from publicly publishing any individual tweet information outside of the tweet’s unique ID. All tweets that can be retrieved by the end user are tweets that are publicly accessible – any tweet that has been deleted, made private, or was tweeted by a user that has since made their account private, was suspended, or deleted their account is no longer accessible. The collection of this dataset was IRB-approved by USC."
HateMM: A Multi-Modal Dataset for Hate Video Classification,"Mithun Das, Rohit Raj, Punyajoy Saha, Binny Mathew, Manish Gupta, Animesh Mukherjee",Ethical Statement,"Ethical Considerations: Our  database  constitutes  videos  with  labeled annotations and does not include any personally identifiable information about any user or the Bitchute channel where the videos have been uploaded.  We  only  analyzed  publicly  available  data. We followed standard ethical guidelines (Rivers and Lewis 2014), not making any attempts to track users across sites or anonymize them. Since the video used in our analysis contain hateful elements, care should be taken to not use it for negative purposes like spreading further hatred or maligning an individual or a community. Biases: Any biases noticed in the dataset are unintentional, and our intention is not bring any individual or a target community to harm. We believe it can be subjective to determine if a video is hateful or not; thus, biases in our gold-labeled data or label distribution are inevitable. Nonetheless, we are confident that the label given to the data is most accurate due to the significant inter-annotator agreement we have achieved. Intended Use: We share our data to encourage more research on hate video classification. We only release the dataset for research purposes and do not grant a license for commercial or malicious use."
HealthE: Recognizing Health Advice & Entities in Online Health Communities,"Joseph Gatto, Parker Seegmiller, Garrett M Johnston, Madhusudan Basak, Sarah Masud Preum",Ethical Impact,"This work only involves humans at the data annotation level. Since the data is collected from OHCs, there is no danger to any human subject in this study concerning the data inHealthE. Given that data from OHCs are layperson-targeted with a general audience in mind, underrepresented communities may not be well represented in this dataset. In other words, OHCs may not formulate advice statements targeting smaller sub-populations of users with diverse factors of social determinants of health. Thus, future applications that leverage HealthE to model patient data or specific types of advice data should consider the bias toward a more generic audience."
Truth Social Dataset,"Patrick Gerard, Nicholas Botzer, Tim Weninger",Ethical Considerations,"The dataset is collected from a publically available resource. While we are releasing user information and potentially personal information,  all  this  information  is  publically available, and users who submit content do so with the explicit intent of making their activity publically and widely visible. This research was observational only. No intervention or treatment was  made  to  the  population;  therefore,  this research was determined to be exempt from full ethical review panel by the University of Notre Dame institutional review board."
Construction of Evaluation Datasets for Trend Forecasting Studies,"Shogo Matsuno, Sakae Mizuki, Takeshi Sakaki",Ethical Statement,"The authors have carefully read and adhered to the AAAICODE  and  ICWSM  Guidelines  with  respect  to  this study and the accompanying dataset. From the perspective of privacy protection, this study assumes that personally identifiable information online is processed in an anonymized format. For example, editor information included as metadata on Wikipedia  is  processed  anonymously.  In  this  case, the object of anonymization is not limited to real names but includes Web service identifiers that can uniquely identify webservice  users.  Furthermore,  as  described  in  §  3.3,  we ensured the reliability of all responses through screening and used ethical considerations in the crowdsourcing questionnaire survey of this study. Specifically, we promised to guarantee the voluntary nature of responses, the right to withdraw during the response process, and data anonymity; in addition, we provided a full explanation of the task to each crowd worker before conducting a questionnaire. All other information in the dataset was obtained from publicly available data on the Internet"
VaxxHesitancy: A Dataset for Studying Hesitancy towards COVID-19 Vaccination on Twitter,"Yida Mu, Mali Jin, Charlie Grimshaw, Carolina Scarton, Kalina Bontcheva, Xingyi Song",Dataset Availability and Ethics Statement,Our  dataset  is  publicly  available  in  compliance  with  the FAIR principles (Wilkinson et al. 2016): Findable: Our dataset has been published in the Zenododataset sharing service with a unique digital object identifier (DOI: 10.5281/zenodo.7601328). We also share the VaxxBERT model via the Huggingface platform21.•Accessible: Original tweets are retrievable based on their tweet IDs using the standard Twitter API22.21https://huggingface.co/GateNLP/covid-vaccine-twitter-bert22https://developer.twitter.com/en/docs/twitter-api/tweets/lookup/api-reference/get-tweets-id1060 Interoperable: Table 8 summarises the dataset structure in CSV format and the description of each column (11 columns in total). CSV datasets are easily imported and processed by most widely used data processing tools. Re-usable: Anyone with a Twitter developer account can re-use our dataset. Using the transformer library (Wolfet al. 2020) researchers can also fine-tune VaxxBERT for other NLP tasks. This work has ethical approval #037567 from our University Research Ethics Committee. Our data collection protocol complies with the Twitter data policies for research (23). We only share tweets IDs following the Twitter API policy and replace annotator names with identifiers.
Capturing the Aftermath of the Dobbs v. Jackson Women’s Health Organization Decision in Google Search Results across the U.S.,"Brooke Perreault, Lan Dau, Anya Wintner, Eni Mustafaraj",Ethical Considerations and FAIRness,"Our  dataset  contains  HTML  pages  that  are automatically generated by  Google  Search  algorithms  in  response to supplied search  phrases.  Google  handles  billions  of such searches daily  and  the  corresponding  web  pages  with the results are not considered content that belongs to Google. Furthermore, courts have ruled that the use of text snippets or images from the indexed websites (or other copyrighted work)  within  Google’s  results  is  “fair  use,”  in accordance with U.S. copyright laws (20). In rare instances, when Googler receives legitimate requests for copyright infringement, it removes a link to the infringing website from the results and replaces its snippet with a copyright infringement notice. If this happens in the future for the pages we have collected, we will not be able to know or take actions. However, given that our dataset will not be used to visit any websites, we hope that this risk is small (20). https://www.flaglerlawgroup.com/a-new-era-for-fair-use-court-changes-fair-use-law-in-google-decision/Some search pages (less than 2%) contain a panel composed of fresh tweets from Twitter, an example of which is shown in Figure 7. As it can be noticed, these tweets contain the names of the accounts from which they were sent. While often tweets are from news organizations, they also include tweets from regular users. If some of these tweets are deleted in the future by the sender, a copy will remain in these pages. Among our parsed results, we only provide the list of the tweet IDs contained in the “raw data’, but no user-specific information. We request that whoever wants to use the tweets from the SERPs should use the Twitter API to find out if these tweets are still publicly available, before scraping them from the SERPs.Our dataset is hosted on the Harvard Dataverse, making it findable and accessible. We have provided CSV files capturing the content of the “raw data,” making the dataset interoperable. Our paper clearly describes the processes followed to collect and extract the data, making it reusable. As such, we believe that we follow the FAIR principles (21)."
Just Another Day on Twitter: A Complete 24 Hours of Twitter Data,"Jurgen Pfeffer, Daniel Matter, Kokil Jaidka, Onur Varol, Afra Mashhadi, Jana Lasser, Dennis Assenmacher, Siqi Wu, Diyi Yang, Cornelia Brantner, Daniel M. Romero, Jahna Otterbacher, Carsten Schwemmer, Kenneth Joseph, David Garcia, Fred Morstatter",Ethics Statement and Data Availability,"Ethics statement. We acknowledge that privacy and ethical concerns are associated with collecting and using social media data for research. However, we took several steps to avoid risks to human subjects since participants no longer opted into being part of our study, in a traditional sense (Zimmer 2020).  In  our  analysis,  we  only  studied  and reported population level, and aggregated observations of our dataset. We share publicly only the tweet IDs with the research community to account for privacy issues and Twitter’s TOS. For this purpose, we use a data sharing and long-term archiving service provided by GESIS - Leibniz Institute for the social sciences, a German infrastructure institute for the social sciences4.With regards to data availability, this repository adheres to the FAIR principles (Wilkinson et al. 2016) as follows:•Findability: In compliance with Twitter’s terms of service, only tweet IDs are made publicly available at DOI:https://doi.org/10.7802/2516.  A  unique  Document Object Identifier  (DOI)  is  associated  with  the  dataset.  Its metadata and licenses are also readily available.•Accessibility: The dataset can be downloaded using standard APIs and communications protocols (the REST API and OAI-PMH).•Interoperability: The data is provided in raw text format.•Reusability:  The  CC  BY  4.0  license  implies  that researchers are free to use the data with proper attribution. In light of the recent changes to Twitter’s APIs, we expect significant limitations when accessing tweets. Consequently, we want to invite the broader research community to approach  one  or  more  of  the  authors  and  collaborators (see  Acknowledgments)  of  this  paper  with  research ideas about what can be done with this dataset. We will be very happy to collaborate with you!"
"Codes, Patterns and Shapes of Contemporary Online Antisemitism and Conspiracy Narratives – an Annotation Guide and Labeled German-Language Dataset in the Context of COVID-19","Elisabeth Steffen, Helena Mihaljevic, Milena Pustet, Nyco Bischoff, Maria do Mar Castro Varela, Yener Bayramoglu, Bahar Oghalai",Data Ethics and Privacy,"Our approach to handle data ethics, privacy and protection follows best practices as documented in (Rivers and Lewis2014).  This  includes  exclusively  collecting  publicly available data and preventing data from being used  to identify authors:  Even  though  Telegram’s  Terms  of  Service state that user names and ids cannot be linked to a user’s phone number as  the  only  personal  data  collected  by  Telegram, we chose to additionally anonymize the dataset by replacing user names, user-ids as well as links to such by USER. Furthermore we decided only to provide our annotated dataset on personal request for research purposes approved for our ethical standards, thereby preventing any attempt of abuse. We also note that the annotator team comprised nine individuals with diverse socio-demographic backgrounds, working in various disciplines (five in political science or sociology and four in data science) with different levels of academic training."
Invasion@Ukraine: Providing and Describing a Twitter Streaming Dataset That Captures the Outbreak of War between Russia and Ukraine in 2022,"Janina Susanne Pohl, Simon Markmann, Dennis Assenmacher, Christian Grimme",Ethical Impact,"From a pure research perspective, this dataset contains valuable information  on  online  communication  patterns  in a temporary historical context. However, there has always been a  conflict  between  full  access  to  online  content  pro-duced  by  individuals  with  individual  interests  in  data and privacy protection on the one hand and the opportunity to get insight into the underlying mechanics of (dis-)information, campaigning,  and  manipulation  content  on  social media platforms on  the  other  hand.  Consequently,  we  are  trying to find an intermediate solution that respects the privacy of individuals while enabling researchers to investigate the dynamics and content of information warfare. We follow the path of other research endeavors that share Twitter data  in  the  context  of  abusive  language  detection (which  is  a  similar  sensitive  topic)  (Founta  et  al.  2018). While we publicly share the complete tweet ID list, we also provide access to the removed content upon explicit request. We only allow academics to access this content and ensure that they agree to our conditions, among other things, not redistributing the dataset and using it for scientific purposes only. We also exclude researchers connected to the immediate war parties, i.e., Russians, Ukrainians, or related organizations, for the time being. The accessible content is reduced to tweet text and stripped from user metadata. In addition, we replaced all user names mentioned in the tweet with pseudonyms and removed the associated tweet IDs to prevent the association of tweet content and specific users. Further, users of the data set should consider the following ethical aspects:•  Researchers using this dataset and deriving conclusions from it are advised to reflect on the implications of their findings in the context of ongoing (dis-) information operations or campaigns. False or speculative conclusions may contribute to mis- or disinformation in the ongoing conflict and influence the public reception of the involved war parties. Researchers using the dataset on the content level should consider the implications of their analysis results on individuals or organizations implicitly mentioned in the textual data.  Hyperlinks  and  indirect  mentions  of  person-s/organizations that we have not been able to anonymize in an  automated  manner  may  cause  direct  or indirect harm to  the  data  subjects.  Therefore,  publishing hidden personal information and/or references to institutions should be treated very carefully. In  the  context  of  using  single  data  artifacts  (like using single tweets in showcases or as representative examples), researchers should consider that the individual“right to be forgotten” (GDPR) has to be respected. As there is no linkage between tweet IDs and textual content in our data set, data users should verify the open availability of specific content or rely on aggregated contentpresentation. Although  some  ethical  conflicts  exist  between possible harmful consequences due to the publication of tweet texts and the provision of research data, we have decided to publish the data. We consider these datasets (as all of the other datasets mentioned  above)  essential  and  of  public interest in the  context  of  the  historical  event  of  the  Russian invasion of  Ukraine  and  the  subsequent  war.  To  mitigate any potential adverse effects of the publication, we have taken various measures to prevent data de-anonymization. At the same time, we ensure that the sensitive text data cannot be accessed uncontrollably but are still available to researchers."
YouNICon: YouTube’s CommuNIty of Conspiracy Videos,"Shao Yi Liaw, Fan Huang, Fabricio Benevenuto, Haewoon Kwak, Jisun An",Ethical Consideration,"We carefully designed our dataset from the data collection period. We collect only publicly available data on YouTube with the  use  of  YouTube’s  Data  API.  Also,  our approach is approved by the Institutional Review Board of SingaporeManagement University (IRB-22-129-A071(922)). To safeguard the interests of our labelers on Amazon MechanicalTurks, they are informed that the content that the conspiracy theories are not true and that withdrawal from the study is without penalty. Helplines are also provided to the participants in the event of any negative emotions."
A Dataset of Coordinated Cryptocurrency-Related Social Media Campaigns,"Karolis Zilius, Tasos Spiliotopoulos, Aad van Moorsel",Broader Impact of the Work and EthicalConsiderations,"Overall,  there  are  numerous  benefits  that  can  be derived from our dataset. We bring awareness to a large number of Bounty events and campaigns that can potentially lead in-experienced  crypto  investors  to  make  poor  financial decisions. Our dataset can be a useful resource for researchers that can  study  the  details  and  structure  of  the  campaigns, gain insights into how the cryptocurrency industry operates and how it interacts with its audience, and develop ways to protect users and inform policy makers. Of course, these benefits need to be considered together with the potential risks of collecting the data and sharing the dataset, especially risks related to unanticipated secondary use (Salganik  2019).  With  regards  to  the  data collection stage, while our dataset includes information and links from a range of social media and other online platforms, we only collected data from the BitcoinTalk forum. This data collection is in line with the Terms and Conditions of the forum, and, in fact, the forum specifically encourages data scraping from its boards14. The collected raw data were held in secure password-protected devices and cloud accounts. A cross-media user dataset presents additional potential misuses compared to a dataset from a single social media platform, such as more extensive profiling and tracking, cyber stalking, and identity theft. In order to minimize the risks associated with sharing the dataset, we removed email addresses. However, we decided to keep other account information, such as social media account IDs and crypto wallet addresses. It was clear to us that these accounts were created for the purpose of participating in Bounty events and there is minimal overlap with forum users’ personal social media accounts or other personal information. The removal of personal information and the use of non-personal (or ”throw-away”) social media accounts by the forum users keeps the risks associated with sharing the dataset relatively low. It is possible that a forum user in the future may decide to delete their account from the forum and their account information will remain  in  our  dataset,  but  we  consider  that  to  be in line with the reasonable privacy expectations of public fo-rum users, especially since a significant amount of content scraping takes place by other forum users in public15. We do not foresee that the release of our dataset can put any of the forum users in any additional danger or risk, as the activities taking place during these Bounty events are currently within the law. Furthermore, while we did not employ any social media APIs to collect the data and, thus, we are not technically subject to any of their Terms and Conditions, we still decided to not share social media content (e.g., tweets) and to only share social media URLs and Tweet IDs. Finally, this work received ethical approval from our institution."
Divergences in Following Patterns between Influential Twitter Users and Their Audiences across Dimensions of Identity,"Suyash Fulay, Nabeel Gillani, Deb Roy",N/A,N/A
Firearms on Twitter: A Novel Object Detection Pipeline,"Ryan Harvey, Remi Lebret, Stephane Massonnet, Karl Aberer, Gianluca Demartini",Ethical Statement,"It  is  important  to  discuss  the  potential  broader  impacts of the current work. On the positive side, the current work can help accelerate and support understandings of ongoing combat situations. More broadly, the techniques presented here can potentially be employed on any small dataset of objects poorly represented by existing object detection datasets. On the negative side, if the techniques fall into the wrong hands, they could aid bad actors in tracking down the civilians responsible for  posting  images  of  particular  combatants.  To limit potential negative impacts on social media users, the Twitter Gun Dataset will not be shared. While the images were collected anonymously it is possible to reverse image search or otherwise track an image back to an account or individual and we would prefer to avoid this possibility."
Auditing Elon Musk’s Impact on Hate Speech and Bots,"Daniel Hickey, Matheus Schmitz, Daniel Fessler, Paul E. Smaldino, Goran Muric, Keith Burghardt",Ethics Statement,"All data were collected from the public Twitter API; identifiable information was removed prior to analysis, minimizing risks to Twitter users. Our work provides several potential benefits for society, including an audit of the steps ostensibly being taken to combat harm on Twitter, and a new way to detect hate speech at scale using commercial APIs as well as a curated list of hate words. Perspective API, which we use to classify hate, is run by Alphabet, a competitor to Twitter, but we believe this does not affect our results."
The Amplification Paradox in Recommender Systems,"Manoel Horta Ribeiro, Veniamin Veselovsky, Robert West",Ethical Considerations,"We do not foresee a negative societal impact coming from this research, which, on the contrary, may help improve algorithmic audits of recommender systems like YouTube."
Host-Centric Social Connectedness of Migrants in Europe on Facebook,"Aparup Khatua, Emilio Zagheni, Ingmar Weber",Ethical Considerations,"Anonymous and aggregate data were obtained through Facebook’s Marketing  API.  Given  the  minimum  group  size of 1000, any individual re-identification risk is minimal. However,  there  is  a  risk  of  group-level  harm  by  mapping vulnerable populations, such as those of a particular faith. To mitigate this risk, Facebook removed targeting attributes related to religion and other sensitive attributes, including the one used in this study5. Note, however, that our study does not target  Muslim  migrants  themselves but natives’ non-Muslimin  the  respective  countries,  limiting  the potential group harm. Still, the removal of the targeting attribute of“friends of people who have engaged with Ramadan” limits the reproducibility. Given the sensitivity of the topic, we commit to sharing our data with other researchers upon request"
Characterizing Coin-Based Voting Governance in DPoS Blockchains,"Chao Li, Runhua Xu, Li Duan",N/A,N/A
Different Affordances on Facebook and SMS Text Messaging Do Not Impede Generalization of Language-Based Predictive Models,"Tingting Liu, Salvatore Giorgi, Xiangyu Tao, Sharath Chandra Guntuku, Douglas Bellew, Brenda Curtis, Lyle Ungar",Broader Impact,"Our  findings  have  important  implications.  Firstly,  our  research highlights the variations in psycho-linguistic features between Facebook and SMS, thus warranting further investigation of  downstream  applications.  Secondly,  future researchers can build predictive models on large-scale social media language and apply them to SMS, which may offer a new approach to address the cost-accuracy trade-off in the context of just-in-time interventions on mobile devices. This study involves human subjects and was approved by the Institutional Review Board (IRB). The data used in this study raise ethical concerns such as handling sensitive personal information (PII) and thus, we have taken measures to securely store, clean, and analyze the data, further data sharing is not possible (3). We use social media, SMS data, and machine learning methods to estimate sensitive attributes like depression. Such estimates can have both positive and negative implications, ranging from providing support to causing discrimination. We must use them with caution"
An Example of (Too Much) Hyper-Parameter Tuning In Suicide Ideation Detection,"Annika Marie Schoene, John Ortega, Silvio Amir, Kenneth Church",N/A,N/A
The Half-Life of a Tweet,"Jurgen Pfeffer, Daniel Matter, Anahit Sargsyan",Research Ethics and Reproducibility,"In this study, we used only publicly available data from Twitter and only utilized Twitter’s own APIs to collect data. We did not send any Tweets and did not interact with other Twitter accounts. Our only variables extracted from the Twitterdata were Tweet IDs, timestamps of when the Tweets were created, and the impression count, which is part of the public metric variable. No Tweet texts, account profile information, or other information that could identify individuals or groups (PII) were analyzed. Reproducibility: All data from the analyses of this article are available online (www.pfeffer.at/data/halflife). The data includes all  Tweet  IDs,  Tweet  creation  time,  and  for each collection iteration for every Tweet, its collection time, and the number of views. Since the views are a function of when the Tweets are collected, we have expanded the JSON response data from the Twitter API that is stored in files with the exact time of every API query."